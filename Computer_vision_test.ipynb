{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab62e39-a0e4-4b1c-aabe-0b9a1fe546ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bokeh in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: Jinja2>=2.9 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh) (1.26.1)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh) (23.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh) (2.1.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh) (10.1.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh) (6.0.1)\n",
      "Requirement already satisfied: tornado>=5.1 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh) (6.3.3)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bokeh) (2023.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Jinja2>=2.9->bokeh) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->bokeh) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->bokeh) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ahmed\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70684718-1daa-4551-8393-57b13538ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "import IPython.display as Disp\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5914f008-3e57-4ec3-8831-a94391c8f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global initialization \n",
    "x_end = y_end=0\n",
    "# All coordonates are initialized to 0\n",
    "class RobotState:\n",
    "    def __init__(self, x=0, y=0, r=0, angle=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.angle = angle \n",
    "\n",
    "robot_state = RobotState()\n",
    "\n",
    "# size of our environment grid\n",
    "num_cases_x = 8  # horizontal cells (valeur arbitraire ici juste pour que ca marche dans mon exemple) \n",
    "num_cases_y = 6   # vertical cells\n",
    "\n",
    "# Initializing our matrix containing the environment information\n",
    "center_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)] #jsp si c'est comme ca qu'on initialise a zero une matrice\n",
    "state_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)]\n",
    "debug_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)]\n",
    "\n",
    "#camera related initialization \n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "#Lower the resolution\n",
    "cam.set(3, 1280)\n",
    "cam.set(4, 720)\n",
    "\n",
    "# Initialize a variable to store the last time an image was acquired\n",
    "last_image_time = time.time()\n",
    "result, image = cam.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793aef31-e678-4e01-9426-89dc85bd27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(image):\n",
    "    \"\"\"    \n",
    "    Preprocess an image for use in computer vision applications.\n",
    "    \n",
    "    Arguments:\n",
    "    image : The input image to be preprocessed.\n",
    "        \n",
    "    Returns:\n",
    "    filtered_image : The preprocessed image.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale for filtering.\n",
    "    image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply bilateral filtering to reduce noise while preserving edges.\n",
    "    bilateral = cv2.bilateralFilter(image_grey, d=5, sigmaColor=25, sigmaSpace=25)\n",
    "    \n",
    "    # Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) for enhancing details.\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    filtered_image1 = clahe.apply(bilateral)\n",
    "    \n",
    "    # Apply Gaussian blur to further use \n",
    "    filtered_image = cv2.GaussianBlur(filtered_image1, (5, 5), 0)\n",
    "    \n",
    "    return filtered_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc612ab-a5cc-4290-8a1e-a9fa0a0e31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_info(keypoints, result_image, robot_state):\n",
    "    \"\"\"\n",
    "    Update the essential information to describe the state of the robot.\n",
    "    \n",
    "    Arguments:\n",
    "        keypoints: Detected keypoints representing potential robot positions.\n",
    "        result_image: The image on which to draw the keypoints.\n",
    "        robot_state: An instance of RobotState containing the coordinates and angle of the robot.\n",
    "        \n",
    "    Returns:\n",
    "        robot_state: The updated RobotState instance.\n",
    "    \"\"\"\n",
    "   \n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = True\n",
    "    params.minCircularity = 0.8\n",
    "    params.maxCircularity = 1\n",
    "        \n",
    "    # Filter by color\n",
    "    params.filterByColor = True\n",
    "\n",
    "    x=y=r=x_big=y_big=r_big=x_small=y_small=r_small=0\n",
    "\n",
    "    # Minimum circle radius we want to detect\n",
    "    small_circle_radius_threshold_max = 14 #(le gros il fais 25 et le petit 18 pour la resolution normale)\n",
    "    small_circle_radius_threshold_min = 5\n",
    "    # Check if any blobs (potential circles) were detected\n",
    "    if keypoints:\n",
    "#---- \n",
    "#     print(f\"{len(keypoints)} blobs detected.\")\n",
    "#----                 \n",
    "        # Draw circles on the original image\n",
    "        for keypoint in keypoints:\n",
    "            x = int(keypoint.pt[0])\n",
    "            y = int(keypoint.pt[1])\n",
    "            r = int(keypoint.size / 2)\n",
    "\n",
    "            if small_circle_radius_threshold_min < r < small_circle_radius_threshold_max:\n",
    "                x_small = x\n",
    "                y_small = y\n",
    "                r_small = r\n",
    "            elif r > small_circle_radius_threshold_max:\n",
    "                x_big = x\n",
    "                y_big = y\n",
    "                r_big = r\n",
    "#----        \n",
    "        # print(robot_state.x,robot_state.y,robot_state.r)\n",
    "        print('r_small =', r_small)\n",
    "        print('r_big =', r_big)\n",
    "        cv2.circle(result_image, (x_big, y_big), r_big, (255, 0, 255), 8) # just to check on the video\n",
    "        cv2.circle(result_image, (x_small, y_small), r_small, (255, 0, 255), 8) # just to check on the video\n",
    "\n",
    "           # print(r)\n",
    "#----\n",
    "        robot_state.x = x_big\n",
    "        robot_state.y = y_big\n",
    "        #Robot orientation = angle between the trajectorie of the robot and the vertical axis\n",
    "        Vect_dir = (x_small - x_big , y_small - y_big)\n",
    "        Vertical = (0, 1)\n",
    "            \n",
    "        dot_product = Vect_dir[0] * Vertical[0] + Vect_dir[1] * Vertical[1]\n",
    "            \n",
    "        magnitude_dir = math.sqrt(Vect_dir[0]**2 + Vect_dir[1]**2)\n",
    "        magnitude_V = math.sqrt(Vertical[0]**2 + Vertical[1]**2)\n",
    "                \n",
    "        # Angle in radiants\n",
    "        if magnitude_dir != 0 and magnitude_V != 0:\n",
    "            angle_rad = math.acos(dot_product / (magnitude_dir * magnitude_V))\n",
    "        else:\n",
    "            angle_rad = 0\n",
    "        # Convertion in degrees\n",
    "        robot_state.angle = math.degrees(angle_rad)\n",
    "# ---\n",
    "#print(robot_state.angle)\n",
    "#---\n",
    "    return robot_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ae3dfa-60c3-4646-80a8-3bfa5ce06824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_setting1(filtered_image,center_matrix,state_matrix,result_image):\n",
    "    \"\"\"\n",
    "    Initializes the grid and updates both the center_matrix and state_matrix with the environment information.\n",
    "    \n",
    "    Arguments:\n",
    "        filtered_image: The image after applying filters, used for contour detection.\n",
    "        center_matrix: A matrix representing the centers of each grid cell.\n",
    "        state_matrix: A matrix representing the state (BLACK, WHITE, ROBOT, TARGET) of each grid cell.\n",
    "        \n",
    "    Returns:\n",
    "        center_matrix, state_matrix.\n",
    "    \"\"\"\n",
    "    #local constant\n",
    "    BLACK = 1\n",
    "    WHITE = 2\n",
    "    ROBOT  = 3\n",
    "    TARGET = 4\n",
    "\n",
    "    black_threshold = 30\n",
    "    white_threshold = 110 \n",
    "    red_threshold_inf = 65\n",
    "    red_threshold_sup = 105\n",
    "    robot_pos_delta_x = 60\n",
    "    robot_pos_delta_y = 80  \n",
    "\n",
    "    min_area_threshold = 75000\n",
    "    # Contour Detection with the Canny filter\n",
    "    countours_image = cv2.Canny(filtered_image, 50, 150, apertureSize=3)\n",
    "    \n",
    "    contours, _ = cv2.findContours(countours_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # grid initializatoin, these points are used to know the grid size\n",
    "    right_pt = left_pt = top_pt = bottom_pt =  [0,0]\n",
    "\n",
    "    center_matrix_prev = copy.deepcopy(center_matrix)\n",
    "    state_matrix_prev = copy.deepcopy(state_matrix)\n",
    "\n",
    "    if contours:\n",
    "        for contour in contours:\n",
    "            # Calculate contour area\n",
    "            area = cv2.contourArea(contour)\n",
    "\n",
    "            # Filter out contours that are too small or too large\n",
    "            if area > min_area_threshold: \n",
    "                #Finding the largest contour (the grid contour)\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "                # Draw the largest contour and centroid\n",
    "                cv2.drawContours(result_image, [largest_contour], -1, (0, 255, 0), 2)\n",
    "                    \n",
    "                # Finding the extrem points\n",
    "                left_pt = tuple(largest_contour[largest_contour[:, :, 0].argmin()][0])\n",
    "                right_pt = tuple(largest_contour[largest_contour[:, :, 0].argmax()][0])\n",
    "                top_pt = tuple(largest_contour[largest_contour[:, :, 1].argmin()][0])\n",
    "                bottom_pt = tuple(largest_contour[largest_contour[:, :, 1].argmax()][0])\n",
    "#----              \n",
    "        cv2.circle(result_image, left_pt, 20, (255, 0, 0), -1)\n",
    "        cv2.circle(result_image, right_pt, 20, (255, 0, 0), -1)\n",
    "        cv2.circle(result_image, top_pt, 20, (255, 0, 0), -1)\n",
    "        cv2.circle(result_image, bottom_pt, 20, (255, 0, 0), -1)\n",
    "\n",
    "        #Debugging only\n",
    "#        print(f\"Leftmost: {left_pt}\")\n",
    "#        print(f\"Rightmost: {right_pt}\")\n",
    "#        print(f\"Topmost: {top_pt}\")\n",
    "#        print(f\"Bottommost: {bottom_pt}\")\n",
    "#----         \n",
    "        # Single cell size computing \n",
    "        case_width = (right_pt[0] - left_pt[0]) // num_cases_x  \n",
    "        case_height = (bottom_pt[1] - top_pt[1]) // num_cases_y\n",
    "        \n",
    "        # Computing the cell center\n",
    "        for i in range(num_cases_y):  \n",
    "            for j in range(num_cases_x): \n",
    "                center_x = left_pt[0] + j * case_width + case_width // 2\n",
    "                center_y = top_pt[1] + i * case_height + case_height // 2\n",
    "                \n",
    "                center_matrix[i][j] = (center_x, center_y)\n",
    "                \n",
    "                #Determine the gray-scale of the center pixel\n",
    "                center_value = filtered_image[center_y, center_x]\n",
    "#----\n",
    "                # Draw a circle to mark the center of each cell\n",
    "                cv2.circle(result_image, (center_x, center_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "                debug_matrix[i][j]=center_value\n",
    "                #print('x: ',center_x-x, ' y: ',center_y-y)\n",
    " #               print(center_value)\n",
    "#----           \n",
    "                #Create the state matrix\n",
    "                if center_value < black_threshold:\n",
    "                    state_matrix[i][j] = BLACK\n",
    "                if center_value > white_threshold:\n",
    "                    state_matrix[i][j] = WHITE\n",
    "                if red_threshold_inf <= center_value <= red_threshold_sup:\n",
    "                    state_matrix[i][j] = TARGET\n",
    "                if 0 <= abs(center_x-robot_state.x) <=  robot_pos_delta_x and 0 <= abs(center_y-robot_state.y) <= robot_pos_delta_y and robot_state.x != 0:\n",
    "                    state_matrix[i][j] = ROBOT\n",
    "    else:\n",
    "        center_matrix = copy.deepcopy(center_matrix_prev)\n",
    "        state_matrix = copy.deepcopy(state_matrix_prev) # comme ca, si on cache on ne detect pas de controu et on garde notre matrice \n",
    "        \n",
    "    return state_matrix, center_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfef5207-3407-45aa-b54d-20e775bd5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def grid_setting(filtered_image, center_matrix, state_matrix):\n",
    "    BLACK = 1\n",
    "    WHITE = 0\n",
    "    black_threshold = 30\n",
    "    white_threshold = 110\n",
    "    red_threshold_inf = 65\n",
    "    red_threshold_sup = 105\n",
    "    robot_pos_delta_x = 60\n",
    "    robot_pos_delta_y = 80\n",
    "    min_area_threshold = 75000\n",
    "\n",
    "    top_right = top_left = bottom_right = bottom_left =  [0,0]\n",
    "    x_center = y_center = 0\n",
    "\n",
    "    contours_image = cv2.Canny(filtered_image, 50, 150, apertureSize=3)\n",
    "    contours, _ = cv2.findContours(contours_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    center_matrix_prev = copy.deepcopy(center_matrix)\n",
    "    state_matrix_prev = copy.deepcopy(state_matrix)\n",
    "    \n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour) > min_area_threshold:\n",
    "            peri = cv2.arcLength(largest_contour, True)\n",
    "            approx = cv2.approxPolyDP(largest_contour, 0.02 * peri, True)\n",
    "            \n",
    "            if len(approx) == 4:\n",
    "                cv2.drawContours(result_image, [approx], -1, (0, 255, 0), 2)\n",
    "                ordered_points = order_points(approx.reshape(4, 2))\n",
    "\n",
    "                destination_points = np.array([\n",
    "                    [0, 0],\n",
    "                    [filtered_image.shape[1] - 1, 0],\n",
    "                    [filtered_image.shape[1] - 1, filtered_image.shape[0] - 1],\n",
    "                    [0, filtered_image.shape[0] - 1]\n",
    "                ], dtype=\"float32\")\n",
    "                \n",
    "                matrix = cv2.getPerspectiveTransform(ordered_points, destination_points)\n",
    "                warped_image = cv2.warpPerspective(filtered_image, matrix, (filtered_image.shape[1], filtered_image.shape[0]))\n",
    "                # Right after you calculate the perspective transformation matrix\n",
    "                inverse_matrix = cv2.invert(matrix)[1]\n",
    "                        \n",
    "       # Compute the cell size using the warped image dimensions\n",
    "                case_width = warped_image.shape[1] // num_cases_x\n",
    "                case_height = warped_image.shape[0] // num_cases_y\n",
    "                \n",
    "                          # When mapping the centers back to the original image space\n",
    "                for i in range(num_cases_y):\n",
    "                    for j in range(num_cases_x):\n",
    "                        center_x = j * case_width + case_width // 2\n",
    "                        center_y = i * case_height + case_height // 2\n",
    "                        \n",
    "                        # Convert to a floating-point type\n",
    "                        float_center = np.array([[[center_x, center_y]]], dtype=np.float32)\n",
    "                        \n",
    "                        # Map the centers back to the original image space using the inverse matrix\n",
    "                        original_center = cv2.perspectiveTransform(float_center, inverse_matrix)\n",
    "                        original_center = tuple(original_center[0][0].astype(int))\n",
    "                        \n",
    "                        # Draw the cell center on the original image\n",
    "                        cv2.circle(result_image, original_center, 5, (0, 0, 255), -1)\n",
    "                        \n",
    "                        # Update center_matrix with the mapped center\n",
    "                        center_matrix[i][j] = original_center\n",
    "                        \n",
    "                        x_center, y_center = original_center  # Unpack the tuple\n",
    "                        center_value = filtered_image[y_center, x_center]  # Access the image at the y, x coordinates\n",
    "                        debug_matrix[i][j] = center_value  # Store the grayscale value\n",
    "                        \n",
    "           \n",
    "                        #Create the state matrix\n",
    "                        if center_value < black_threshold:\n",
    "                            state_matrix[i][j] = BLACK\n",
    "                        if center_value > white_threshold:\n",
    "                            state_matrix[i][j] = WHITE\n",
    "                        if red_threshold_inf <= center_value <= red_threshold_sup:\n",
    "                            x_end, y_end = center_matrix[i][j]\n",
    "                            state_matrix[i][j] = WHITE\n",
    "                        \n",
    "    else:\n",
    "        center_matrix = copy.deepcopy(center_matrix_prev)\n",
    "        state_matrix = copy.deepcopy(state_matrix_prev) # comme ca, si on cache on ne detect pas de controu et on garde notre matrice \n",
    "        \n",
    "    return state_matrix, center_matrix, x_end, y_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f2fd1a0-70f8-47fc-918c-2a58dbecc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_plot(num_cases_x,num_cases_y):\n",
    "    \"\"\"\n",
    "    Helper function to create a figure of the desired dimensions & grid\n",
    "    \n",
    "    :param max_val: dimension of the map along the x and y dimensions\n",
    "    :return: the fig and ax objects.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    \n",
    "    major_ticks = np.arange(0, num_cases_x+1, 1)\n",
    "    minor_ticks = np.arange(0, num_cases_y+1, 1)\n",
    "    ax.set_xticks(major_ticks)\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    ax.set_yticks(major_ticks)\n",
    "    ax.set_yticks(minor_ticks, minor=True)\n",
    "    ax.grid(which='minor', alpha=0.2)\n",
    "    ax.grid(which='major', alpha=0.5)\n",
    "    ax.set_ylim([-1,num_cases_y])\n",
    "    ax.set_xlim([-1,num_cases_x])\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7280099a-cd18-464a-beab-541e0954a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_movements_4n():\n",
    "    \"\"\"\n",
    "    Get all possible 4-connectivity movements (up, down, left right).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0)]\n",
    "\n",
    "def _get_movements_8n():\n",
    "    \"\"\"\n",
    "    Get all possible 8-connectivity movements. Equivalent to get_movements_in_radius(1)\n",
    "    (up, down, left, right and the 4 diagonals).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    s2 = math.sqrt(2)\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0),\n",
    "            (1, 1, s2),\n",
    "            (-1, 1, s2),\n",
    "            (-1, -1, s2),\n",
    "            (1, -1, s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd50078-0e53-477e-bf7f-76f7d7f7d13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0929679f-11c7-453e-af2f-2fd78948116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reconstruct_path(cameFrom, current):\n",
    "    \"\"\"\n",
    "    Recurrently reconstructs the path from start node to the current node\n",
    "    :param cameFrom: map (dictionary) containing for each node n the node immediately \n",
    "                     preceding it on the cheapest path from start to n \n",
    "                     currently known.\n",
    "    :param current: current node (x, y)\n",
    "    :return: list of nodes from start to current node\n",
    "    \"\"\"\n",
    "    total_path = [current]\n",
    "    while current in cameFrom.keys():\n",
    "        # Add where the current node came from to the start of the list\n",
    "        total_path.insert(0, cameFrom[current]) \n",
    "        current=cameFrom[current]\n",
    "        \n",
    "    print(total_path)\n",
    "    return total_path\n",
    "\n",
    "def A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\", num_cases_x=num_cases_x, num_cases_y=num_cases_y):\n",
    "    \"\"\"\n",
    "    A* for 2D occupancy grid. Finds a path from start to goal.\n",
    "    h is the heuristic function. h(n) estimates the cost to reach goal from node n.\n",
    "    :param start: start node (x, y)\n",
    "    :param goal_m: goal node (x, y)\n",
    "    :param occupancy_grid: the grid map\n",
    "    :param movement: select between 4-connectivity ('4N') and 8-connectivity ('8N', default)\n",
    "    :return: a tuple that contains: (the resulting path in meters, the resulting path in data array indices)\n",
    "    \"\"\"\n",
    "    # -----------------------------------------\n",
    "    # DO NOT EDIT THIS PORTION OF CODE\n",
    "    # -----------------------------------------\n",
    "    # Check if the start and goal are within the boundaries of the map\n",
    "    for point in [start, goal]:\n",
    "        for coord in point:\n",
    "            assert coord>=0 and coord<num_cases_x, \"start or end goal not contained in the map\"\n",
    "            assert coord>=0 and coord<num_cases_y, \"start or end goal not contained in the map\"\n",
    "    \n",
    "    # check if start and goal nodes correspond to free spaces\n",
    "    if occupancy_grid[start[0], start[1]]:\n",
    "        raise Exception('Start node is not traversable')\n",
    "\n",
    "    if occupancy_grid[goal[0], goal[1]]:\n",
    "        raise Exception('Goal node is not traversable')\n",
    "    \n",
    "    # get the possible movements corresponding to the selected connectivity\n",
    "    if movement_type == '4N':\n",
    "        movements = _get_movements_4n()\n",
    "    elif movement_type == '8N':\n",
    "        movements = _get_movements_8n()\n",
    "    else:\n",
    "        raise ValueError('Unknown movement')\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # A* Algorithm implementation - feel free to change the structure / use another pseudo-code\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # The set of visited nodes that need to be (re-)expanded, i.e. for which the neighbors need to be explored\n",
    "    # Initially, only the start node is known.\n",
    "    openSet = [start]\n",
    "    \n",
    "    # The set of visited nodes that no longer need to be expanded.\n",
    "    closedSet = []\n",
    "\n",
    "    # For node n, cameFrom[n] is the node immediately preceding it on the cheapest path from start to n currently known.\n",
    "    cameFrom = dict()\n",
    "\n",
    "    # For node n, gScore[n] is the cost of the cheapest path from start to n currently known.\n",
    "    gScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    gScore[start] = 0\n",
    "\n",
    "    # For node n, fScore[n] := gScore[n] + h(n). map with default value of Infinity\n",
    "    fScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    fScore[start] = h[start]\n",
    "\n",
    "    # while there are still elements to investigate\n",
    "    while openSet != []:\n",
    "        \n",
    "        #the node in openSet having the lowest fScore[] value\n",
    "        fScore_openSet = {key:val for (key,val) in fScore.items() if key in openSet}\n",
    "        current = min(fScore_openSet, key=fScore_openSet.get)\n",
    "        del fScore_openSet\n",
    "        \n",
    "        #If the goal is reached, reconstruct and return the obtained path\n",
    "        if current == goal:\n",
    "            print(closedSet)\n",
    "            return reconstruct_path(cameFrom, current), closedSet\n",
    "\n",
    "        openSet.remove(current)\n",
    "        closedSet.append(current)\n",
    "        \n",
    "        #for each neighbor of current:\n",
    "        for dx, dy, deltacost in movements:\n",
    "            \n",
    "            neighbor = (current[0]+dx, current[1]+dy)\n",
    "            \n",
    "            # if the node is not in the map, skip\n",
    "            if (neighbor[0] >= occupancy_grid.shape[0]) or (neighbor[1] >= occupancy_grid.shape[1]) or (neighbor[0] < 0) or (neighbor[1] < 0):\n",
    "                continue\n",
    "            \n",
    "            # if the node is occupied or has already been visited, skip\n",
    "            if (occupancy_grid[neighbor[0], neighbor[1]]) or (neighbor in closedSet): \n",
    "                continue\n",
    "                \n",
    "            # d(current,neighbor) is the weight of the edge from current to neighbor\n",
    "            # tentative_gScore is the distance from start to the neighbor through current\n",
    "            tentative_gScore = gScore[current] + deltacost\n",
    "            \n",
    "            if neighbor not in openSet:\n",
    "                openSet.append(neighbor)\n",
    "                \n",
    "            if tentative_gScore < gScore[neighbor]:\n",
    "                # This path to neighbor is better than any previous one. Record it!\n",
    "                cameFrom[neighbor] = current\n",
    "                gScore[neighbor] = tentative_gScore\n",
    "                fScore[neighbor] = gScore[neighbor] + h[neighbor]\n",
    "\n",
    "    # Open set is empty but goal was never reached\n",
    "    print(\"No path found to goal\")\n",
    "    return [], closedSet\n",
    "\n",
    "def truncate_coordinate(x,y):\n",
    "        x = x/100\n",
    "        y = y/100\n",
    "        x_out = round(x)\n",
    "        y_out = round(y)\n",
    "  \n",
    "        return(x_out,y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bbb269f-d8c6-44e9-a8c1-84fde5b1f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end goal\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# DO NOT EDIT THIS PORTION OF CODE - \n",
    "# EXECUTION AND PLOTTING OF THE ALGORITHM\n",
    "# -----------------------------------------\n",
    "    \n",
    "    \n",
    "# List of all coordinates in the grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b854348-6e19-47b2-b801-f403691b688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 1\n",
    "while True:\n",
    "    start_time = time.time()  # Record the start time\n",
    "    ret, frame = cam.read()\n",
    "    if ret:\n",
    "        result_image = frame.copy()  # Initialiser result_image avec une copie de l'image actuelle\n",
    "        \n",
    "        filtered_image = pre_processing(result_image)\n",
    "        plt.imshow(cv2.cvtColor(filtered_image, cv2.COLOR_BGR2RGB))\n",
    "        # Blob detector parameters for circle detection\n",
    "        params = cv2.SimpleBlobDetector_Params()\n",
    "        \n",
    "        # Create a blob detector with the configured parameters\n",
    "        detector = cv2.SimpleBlobDetector_create(params)\n",
    "        \n",
    "        # Detect blobs in the image\n",
    "        keypoints = detector.detect(filtered_image)\n",
    "        \n",
    "        # Update the info about the robot\n",
    "        robot_state = robot_info(keypoints, result_image, robot_state)\n",
    "\n",
    "        state_matrix, center_matrix, x_end, y_end = grid_setting(filtered_image,center_matrix,state_matrix)\n",
    "        if state == 0 :\n",
    "            \n",
    "            continue\n",
    "        else :\n",
    "\n",
    "               \n",
    "            fig, ax = create_empty_plot(num_cases_x,num_cases_y)\n",
    "                \n",
    "                # Creating the occupancy grid\n",
    "            data = np.array(state_matrix)\n",
    "                #data = np.array([[0, 0, 0, 0, 1, 1],\n",
    "                # [0, 1, 0, 1, 1, 0],\n",
    "                # [0 ,0, 0, 0, 0, 0],\n",
    "                # [0, 1, 0, 1, 1, 0],\n",
    "                # [0, 1, 0, 1, 0, 0],\n",
    "                # [1, 0, 1, 0, 0, 1],\n",
    "                # [0, 1, 1, 0, 0, 1],\n",
    "                # [0 ,1, 0,0 , 0, 1]])\n",
    "            cmap = colors.ListedColormap(['white', 'red']) # Select the colors with which to display obstacles and free cells    \n",
    "                \n",
    "                # Converting the random values into occupied and free cells\n",
    "            limit = 0\n",
    "            occupancy_grid = data.copy()\n",
    "            occupancy_grid[data>limit] = 1\n",
    "            occupancy_grid[data<=limit] = 0\n",
    "            print(occupancy_grid)\n",
    "                \n",
    "                # Displaying the map\n",
    "            ax.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "            plt.title(\"Map : free cells in white, occupied cells in red\");\n",
    "            start_x = robot_state.x\n",
    "            start_y = robot_state.y\n",
    "            start = truncate_coordinate(start_x,start_y)\n",
    "            goal = truncate_coordinate(x_end,y_end)\n",
    "            state = 0\n",
    "                # Run the A* algorithm\n",
    "            path, visitedNodes = A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\")\n",
    "            path = np.array(path).reshape(-1, 2).transpose()\n",
    "            visitedNodes = np.array(visitedNodes).reshape(-1, 2).transpose()\n",
    "            x,y = np.mgrid[0:num_cases_x:1, 0:num_cases_y:1]\n",
    "            pos = np.empty(x.shape + (2,))\n",
    "            pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "            pos = np.reshape(pos, (x.shape[0]*x.shape[1], 2))\n",
    "            coords = list([(int(x[0]), int(x[1])) for x in pos])\n",
    "                \n",
    "                # Define the heuristic, here = distance to goal ignoring obstacles\n",
    "            h = np.linalg.norm(pos - goal, axis=-1)\n",
    "            h = dict(zip(coords, h))\n",
    "                \n",
    "                # Run the A* algorithm\n",
    "            path, visitedNodes = A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\")\n",
    "            path = np.array(path).reshape(-1, 2).transpose()\n",
    "            visitedNodes = np.array(visitedNodes).reshape(-1, 2).transpose()\n",
    "                \n",
    "                # Displaying the map\n",
    "            fig_astar, ax_astar = create_empty_plot(num_cases_x,num_cases_y)\n",
    "            ax_astar.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "                \n",
    "                # Plot the best path found and the list of visited nodes\n",
    "            ax_astar.scatter(visitedNodes[0], visitedNodes[1], marker=\"o\", color = 'orange');\n",
    "            ax_astar.plot(path[0], path[1], marker=\"o\", color = 'blue');\n",
    "            ax_astar.scatter(start[0], start[1], marker=\"o\", color = 'green', s=200);\n",
    "            ax_astar.scatter(goal[0], goal[1], marker=\"o\", color = 'purple', s=200);\n",
    "                # Displaying the map\n",
    "            fig_astar, ax_astar = create_empty_plot(num_cases_x,num_cases_y)\n",
    "            ax_astar.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "                \n",
    "                # Plot the best path found and the list of visited nodes\n",
    "            ax_astar.scatter(visitedNodes[0], visitedNodes[1], marker=\"o\", color = 'orange');\n",
    "            ax_astar.plot(path[0], path[1], marker=\"o\", color = 'blue');\n",
    "            ax_astar.scatter(start[0], start[1], marker=\"o\", color = 'green', s=200);\n",
    "            ax_astar.scatter(goal[0], goal[1], marker=\"o\", color = 'purple', s=200);\n",
    "            \n",
    "        \n",
    "        #print(x_end,y_end)\n",
    "        print('state_matrix : ')\n",
    "        print(state_matrix[0])\n",
    "        print(state_matrix[1])\n",
    "        print(state_matrix[2])\n",
    "        print(state_matrix[3])\n",
    "        print(state_matrix[4])\n",
    "        print(state_matrix[5])\n",
    "\n",
    "        print('debug_matrix : ')\n",
    "        print(debug_matrix[0])\n",
    "        print(debug_matrix[1])\n",
    "        print(debug_matrix[2])\n",
    "        print(debug_matrix[3])\n",
    "        print(debug_matrix[4])\n",
    "        print(debug_matrix[5])\n",
    "        \n",
    "        cv2.imshow('Live Footage', result_image)\n",
    "\n",
    "        #if you click on any key it stops the program\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "#-----        \n",
    "  #      print(state_matrix)\n",
    "#-----\n",
    "            # Wait until a second has passed since the start of the iteration\n",
    "        while time.time() - start_time < 1:\n",
    "            time.sleep(0.01) \n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the camera and close the window\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(1, 5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e6fc6-fd5d-4141-b9d1-b44695a92175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a1f4f-edf6-4cc7-ab49-6c6478f0d73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
