{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6207d6c4-dc7c-4660-8daf-f6c707c6abc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call here. Maybe you meant '==' instead of '='? (1283573759.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    timer_led()=\"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "timer0 = {\n",
    "    \"timer.period[0]\": [1000],\n",
    "}\n",
    "aw(node.set_variables(timer0))\n",
    "\n",
    "timer_led()=\"\"\"\n",
    "    onevent timer_led\n",
    "        on  = not on \n",
    "        if on:\n",
    "            leds_top =[32,32,0]\n",
    "        else: \n",
    "            leds_top =[0,0,0]\n",
    "\"\"\"\n",
    "\n",
    "onevent(timer_led)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70684718-1daa-4551-8393-57b13538ba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node 1c581bcb-86c8-4db2-ad39-981e3520a6da"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import asyncio\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "import IPython.display as Disp\n",
    "from ipywidgets import widgets\n",
    "\n",
    "from ExtendedKalmanFilter import EKF\n",
    "\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5914f008-3e57-4ec3-8831-a94391c8f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#astolfi (controlleur avec tout dansle cours le tout premier de mobile)\n",
    "#onevent timer \n",
    "#dans le premier tu update justre la vitesse des moteurs\n",
    "#dans le deuxieme tu check les obstacles\n",
    "#global initialization \n",
    "x_end = y_end=0\n",
    "# All coordonates are initialized to 0\n",
    "class RobotState:\n",
    "    def __init__(self, x=0, y=0, r=0, angle=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.angle = angle \n",
    "\n",
    "robot_state = RobotState()\n",
    "\n",
    "\n",
    "# size of our environment grid\n",
    "num_cases_x = 8  # horizontal cells (valeur arbitraire ici juste pour que ca marche dans mon exemple) \n",
    "num_cases_y = 6   # vertical cells\n",
    "\n",
    "# Initializing our matrix containing the environment information\n",
    "#center_matrix = np.full((num_cases_y, num_cases_x), fill_value=None)\n",
    "#state_matrix  = np.full((num_cases_y, num_cases_x), fill_value=None)\n",
    "#debug_matrix  = np.full((num_cases_y, num_cases_x), fill_value=None)\n",
    "center_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)] #jsp si c'est comme ca qu'on initialise a zero une matrice\n",
    "state_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)]\n",
    "debug_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)]\n",
    "\n",
    "#camera related initialization \n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "#Lower the resolution\n",
    "cam.set(3, 1280)\n",
    "cam.set(4, 720)\n",
    "\n",
    "# Initialize a variable to store the last time an image was acquired\n",
    "#last_image_time = time.time()\n",
    "#result, image = cam.read()\n",
    "\n",
    "state = 1\n",
    "should_break = False\n",
    "\n",
    "# initializes filter and time stamp\n",
    "ekf = None\n",
    "last_time = time.monotonic()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5167a2fc-01c7-4730-b025-c2f100fa456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle_degrees(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculate the angle in degrees between two points (x1, y1) and (x2, y2).\n",
    "    \"\"\"\n",
    "#    print(f\"x1 type: {type(x1)}, value: {x1}\")\n",
    "#    print(f\"x2 type: {type(x2)}, value: {x2}\")\n",
    "\n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    angle_rad = math.atan2(delta_y, delta_x)\n",
    "    \n",
    "    # Convert angle to degrees\n",
    "    angle_degrees = math.degrees(angle_rad)\n",
    "    \n",
    "    # Convert angle to be in the range [0, 360)\n",
    "    # angle_degrees = angle_degrees % 360\n",
    "#    print(angle_degrees)\n",
    "    return angle_degrees\n",
    "\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points (x1, y1) and (x2, y2).\n",
    "    \"\"\"\n",
    "    distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793aef31-e678-4e01-9426-89dc85bd27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(image):\n",
    "    \"\"\"    \n",
    "    Preprocess an image for use in computer vision applications.\n",
    "    \n",
    "    Arguments:\n",
    "    image : The input image to be preprocessed.\n",
    "        \n",
    "    Returns:\n",
    "    filtered_image : The preprocessed image.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale for filtering.\n",
    "    image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply bilateral filtering to reduce noise while preserving edges.\n",
    "    bilateral = cv2.bilateralFilter(image_grey, d=5, sigmaColor=25, sigmaSpace=25)\n",
    "    \n",
    "    # Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) for enhancing details.\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    filtered_image1 = clahe.apply(bilateral)\n",
    "    \n",
    "    # Apply Gaussian blur to further use \n",
    "    filtered_image = cv2.GaussianBlur(filtered_image1, (5, 5), 0)\n",
    "    \n",
    "    return filtered_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc612ab-a5cc-4290-8a1e-a9fa0a0e31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_info(keypoints, result_image,params):\n",
    "    global robot_state\n",
    "    \"\"\"\n",
    "    Update the essential informations to describe the state of the robot.\n",
    "    \n",
    "    Arguments:\n",
    "        keypoints: Detected keypoints representing potential robot positions.\n",
    "        result_image: The image on which to draw the keypoints.\n",
    "        robot_state: An instance of RobotState containing the coordinates and angle of the robot.\n",
    "        \n",
    "    Returns:\n",
    "        robot_state: The updated RobotState instance.\n",
    "    \"\"\"\n",
    "   \n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = True\n",
    "    params.minCircularity = 0.8\n",
    "    params.maxCircularity = 1\n",
    "        \n",
    "    # Filter by color\n",
    "    params.filterByColor = True\n",
    "\n",
    "    x=y=r=x_big=y_big=r_big=x_small=y_small=r_small=0 # peut etre je peux enlever ca \n",
    "\n",
    "    # Minimum circle radius we want to detect\n",
    "    small_circle_radius_threshold_max = 13 #(le gros il fais 25 et le petit 18 pour la resolution normale)\n",
    "    small_circle_radius_threshold_min = 5\n",
    "    # Check if any blobs (potential circles) were detected\n",
    "    if keypoints:\n",
    "           \n",
    "        # Draw circles on the original image\n",
    "        for keypoint in keypoints:\n",
    "            x = int(keypoint.pt[0])\n",
    "            y = int(keypoint.pt[1])\n",
    "            r = int(keypoint.size / 2)\n",
    "\n",
    "            if small_circle_radius_threshold_min < r < small_circle_radius_threshold_max:\n",
    "                x_small = x\n",
    "                y_small = y\n",
    "                r_small = r\n",
    "            elif r > small_circle_radius_threshold_max:\n",
    "                x_big = x\n",
    "                y_big = y\n",
    "                r_big = r\n",
    "#----        \n",
    "        # print(robot_state.x,robot_state.y,robot_state.r)\n",
    "   #     print('r_small =', r_small)\n",
    "  #      print('r_big =', r_big)\n",
    "        cv2.circle(result_image, (x_big, y_big), r_big, (255, 0, 255), 8) # just to check on the video\n",
    "        cv2.circle(result_image, (x_small, y_small), r_small, (255, 0, 255), 8) # just to check on the video\n",
    "\n",
    "           # print(r)\n",
    "#----\n",
    "        robot_state.x = x_big\n",
    "        robot_state.y = y_big\n",
    "        \n",
    "        #Robot orientation = angle between the trajectorie of the robot and the vertical axis\n",
    "        # moins l'angle pck l'origine est inversée par rapport a la map\n",
    "        robot_state.angle = -calculate_angle_degrees(x_big, y_big, x_small, y_small)\n",
    "\n",
    "    return robot_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80148a6-7eaa-43f0-9cdb-9020b25f5245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_robot_cam():\n",
    "    \"\"\"\n",
    "    Update the essential informations to describe the state of the robot and of the map.\n",
    "    \n",
    "    Arguments:\n",
    "       \n",
    "    Returns:\n",
    "        robot_state: The updated RobotState instance.\n",
    "        center_matrix:\n",
    "        x_end, y_end:\n",
    "        result_image: Image with all the analysis \n",
    "    \"\"\"\n",
    "    global robot_state, result_image, center_matrix, state_matrix,data,x_end,y_end\n",
    "    image_not_good = True\n",
    "    while image_not_good: \n",
    "        image_not_good = False\n",
    "        ret, frame = cam.read()\n",
    "        if ret:\n",
    "            result_image = frame.copy()  # Initialiser result_image avec une copie de l'image actuelle\n",
    "            filtered_image = pre_processing(result_image)\n",
    "             # Blob detector parameters for circle detection\n",
    "            params = cv2.SimpleBlobDetector_Params()\n",
    "            \n",
    "            # Create a blob detector with the configured parameters\n",
    "            detector = cv2.SimpleBlobDetector_create(params)\n",
    "            \n",
    "            # Detect blobs in the image\n",
    "            keypoints = detector.detect(filtered_image)\n",
    "            \n",
    "            # Update the info about the robot\n",
    "            robot_state = robot_info(keypoints, result_image,params)\n",
    "    \n",
    "            state_matrix, center_matrix, x_end, y_end = grid_setting(filtered_image)\n",
    "            \n",
    "            state_matrix = np.array(state_matrix)\n",
    "            data = symetrie_lignes(state_matrix)\n",
    "            for i in range(num_cases_y):\n",
    "                for j in range(num_cases_x):\n",
    "                    if state_matrix[i][j] == None: \n",
    "                        image_not_good = True\n",
    "        else:\n",
    "            print('no image found')\n",
    "            image_not_good = False\n",
    "\n",
    "    return data, center_matrix, x_end, y_end, robot_state, result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_time():\n",
    "    \"\"\"Updates the last time checkpoint and returns the time spent since\"\"\"\n",
    "    global last_time\n",
    "    time_now = time.monotonic()\n",
    "    dt = time_now-last_time\n",
    "    last_time = time_now\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speed(right, left):\n",
    "    \"\"\"Retrieves the speed of the robot. Constant coefficient to converse speed of motors to units we want\n",
    "    returns: np.array- [linear_speed, angular speed] in pixels/sec and angle/sec\n",
    "    \"\"\"\n",
    "    coeff_lin = 176/7\n",
    "    coeff_angular = 37/200\n",
    "    linear = ((right + left)/2) * coeff_lin\n",
    "    angular = (left - right) * coeff_angular\n",
    "    return np.array([linear, angular])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_call(right, left, dt):\n",
    "    \"\"\"Makes the call to the filter using the initialised ekf\n",
    "        Args:\n",
    "        right: right speed of the motor in thymio unit (same unit as we give the motor)\n",
    "        left: left speed\n",
    "        Returns: estimated positions x, y, angle in pixels, degrees\n",
    "        \"\"\"\n",
    "    global ekf\n",
    "    #dt = update_time()\n",
    "    speed = get_speed(right, left)\n",
    "    _, _, _, _, position, _ = info_robot_cam()\n",
    "    cam_pos = np.array([position.x, position.y, position.angle])\n",
    "    return ekf.filter(cam_pos, speed, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfef5207-3407-45aa-b54d-20e775bd5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    \"\"\"\n",
    "    Orders the corners of a rectangle or quadrilateral in a consistent way: \n",
    "    top-left, top-right, bottom-right, bottom-left. \n",
    "\n",
    "    Parameters:\n",
    "    - pts: A numpy array of four points (x, y)\n",
    "\n",
    "    Returns:\n",
    "    - A reordered numpy array of points in the order [top-left, top-right, bottom-right, bottom-left].\n",
    "    \"\"\"\n",
    "\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = np.diff(pts, axis=1)\n",
    "\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def grid_setting(filtered_image):\n",
    "    \"\"\"\n",
    "    Processes a filtered image to identify and analyze a grid, which is assumed to be the largest detected contour.\n",
    "\n",
    "    Parameters:\n",
    "    - filtered_image: A pre-processed image where contours can be easily detected, typically a grayscale or thresholded image.\n",
    "\n",
    "    Returns:\n",
    "    - The updated state matrix, center matrix, and the end coordinates of a specific goal within the grid.\n",
    "    \"\"\"\n",
    "    global center_matrix, state_matrix,result_image\n",
    "\n",
    "    #local variables used for the good detection of the different parts of the grid\n",
    "    BLACK = 1\n",
    "    WHITE = 0\n",
    "    black_threshold = 40\n",
    "    white_threshold = 101\n",
    "    red_threshold_inf = 41\n",
    "    red_threshold_sup = 100\n",
    "    robot_pos_delta_x = 55\n",
    "    robot_pos_delta_y = 55\n",
    "    min_area_threshold = 75000\n",
    "    \n",
    "    x_center = y_center = x_end = y_end = 0\n",
    "\n",
    "    contours_image = cv2.Canny(filtered_image, 50, 150, apertureSize=3)\n",
    "    contours, _ = cv2.findContours(contours_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    center_matrix_prev = copy.deepcopy(center_matrix)\n",
    "    state_matrix_prev = copy.deepcopy(state_matrix)\n",
    "\n",
    "    x_end_prev = x_end\n",
    "    y_end_prev = y_end\n",
    "    \n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour) > min_area_threshold:\n",
    "            \n",
    "            # We first approximate the contour to a rectangle\n",
    "            peri = cv2.arcLength(largest_contour, True) #return the perimeter of our contour \n",
    "            approx = cv2.approxPolyDP(largest_contour, 0.02 * peri, True)  #return the number of the corners of the detected shape\n",
    "            #0.02* peri: This value represents the maximum distance between the original curve and its approximation\n",
    "            \n",
    "            if len(approx) == 4:\n",
    "                cv2.drawContours(result_image, [approx], -1, (0, 255, 0), 2)\n",
    "                \n",
    "                ordered_points = order_points(approx.reshape(4, 2))\n",
    "                destination_points = np.array([\n",
    "                    [0, 0],\n",
    "                    [filtered_image.shape[1] - 1, 0],\n",
    "                    [filtered_image.shape[1] - 1, filtered_image.shape[0] - 1],\n",
    "                    [0, filtered_image.shape[0] - 1]\n",
    "                ], dtype=\"float32\")\n",
    "                \n",
    "                matrix = cv2.getPerspectiveTransform(ordered_points, destination_points)\n",
    "                warped_image = cv2.warpPerspective(filtered_image, matrix, (filtered_image.shape[1], filtered_image.shape[0]))\n",
    "                inverse_matrix = cv2.invert(matrix)[1]\n",
    "\n",
    "                #----------- DISPLAY THE TRANSFORMED IMAGE\n",
    "                # Convert the image from BGR to RGB format (OpenCV loads images in BGR by default)\n",
    "             #   warped_image_rgb = cv2.cvtColor(warped_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Display the image in the Jupyter Notebook\n",
    "               # display(Image(data=warped_image_rgb))\n",
    "\n",
    "                #------------\n",
    "                        \n",
    "                case_width = warped_image.shape[1] // num_cases_x\n",
    "                case_height = warped_image.shape[0] // num_cases_y\n",
    "\n",
    "                #correction\n",
    "                distortion_corr = np.array([0.9501, 0.9740, 0.9876, 1, 1.0064, 1.0092, 1.0152, 1.0164])\n",
    "                for i in range(num_cases_y):\n",
    "                    for j in range(num_cases_x):\n",
    "                        center_x = j * case_width * distortion_corr[j] + case_width // 2\n",
    "                        center_y = i * case_height + case_height // 2\n",
    "\n",
    "                        #conversion in a numpy array of type float32 as this format is required by OpenCV functions for transformations.\n",
    "                        float_center = np.array([[[center_x, center_y]]], dtype=np.float32)\n",
    "                        \n",
    "                        original_center = cv2.perspectiveTransform(float_center, inverse_matrix)\n",
    "                        original_center = tuple(original_center[0][0].astype(int))\n",
    "                        \n",
    "                        cv2.circle(result_image, original_center, 5, (0, 0, 255), -1)\n",
    "                        \n",
    "                        center_matrix[i][j] = original_center\n",
    "                        \n",
    "                        x_center, y_center = original_center  \n",
    "                        center_value = filtered_image[y_center, x_center]  \n",
    "                        debug_matrix[i][j] = center_value  ###_________________\n",
    " #                       print('debug',debug_matrix)\n",
    "                        if center_value < black_threshold :\n",
    "                            if abs(x_center-robot_state.x) <= robot_pos_delta_x and abs(y_center-robot_state.y) <= robot_pos_delta_y:\n",
    "                                state_matrix[i][j] = WHITE\n",
    "                            else:\n",
    "                                state_matrix[i][j] = BLACK     \n",
    "                        if center_value > white_threshold:\n",
    "                            state_matrix[i][j] = WHITE\n",
    "                        if red_threshold_inf <= center_value <= red_threshold_sup:\n",
    "                            x_end, y_end = center_matrix[i][j]\n",
    "                            state_matrix[i][j] = WHITE\n",
    "\n",
    "                        \n",
    "    else:\n",
    "        center_matrix = copy.deepcopy(center_matrix_prev)\n",
    "        state_matrix = copy.deepcopy(state_matrix_prev) # _____________ here maybe a condition\n",
    "        x_end = x_end_prev\n",
    "        y_end = y_end_prev\n",
    "        \n",
    "    return state_matrix, center_matrix, x_end, y_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f2fd1a0-70f8-47fc-918c-2a58dbecc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_plot(num_cases_x,num_cases_y):\n",
    "    \"\"\"\n",
    "    Helper function to create a figure of the desired dimensions & grid\n",
    "    \n",
    "    :param max_val: dimension of the map along the x and y dimensions\n",
    "    :return: the fig and ax objects.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    \n",
    "    major_ticks = np.arange(0, num_cases_x+1, 1)\n",
    "    minor_ticks = np.arange(0, num_cases_y+1, 1)\n",
    "    ax.set_xticks(major_ticks)\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    ax.set_yticks(major_ticks)\n",
    "    ax.set_yticks(minor_ticks, minor=True)\n",
    "    ax.grid(which='minor', alpha=0.2)\n",
    "    ax.grid(which='major', alpha=0.5)\n",
    "    ax.set_ylim([-1,num_cases_y])\n",
    "    ax.set_xlim([-1,num_cases_x])\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7280099a-cd18-464a-beab-541e0954a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_movements_4n():\n",
    "    \"\"\"\n",
    "    Get all possible 4-connectivity movements (up, down, left right).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0)]\n",
    "\n",
    "def _get_movements_8n():\n",
    "    \"\"\"\n",
    "    Get all possible 8-connectivity movements. Equivalent to get_movements_in_radius(1)\n",
    "    (up, down, left, right and the 4 diagonals).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    s2 = math.sqrt(2)\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0),\n",
    "            (1, 1, s2),\n",
    "            (-1, 1, s2),\n",
    "            (-1, -1, s2),\n",
    "            (1, -1, s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0929679f-11c7-453e-af2f-2fd78948116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_path(cameFrom, current):\n",
    "    \"\"\"\n",
    "    Recurrently reconstructs the path from start node to the current node\n",
    "    :param cameFrom: map (dictionary) containing for each node n the node immediately \n",
    "                     preceding it on the cheapest path from start to n \n",
    "                     currently known.\n",
    "    :param current: current node (x, y)\n",
    "    :return: list of nodes from start to current node\n",
    "    \"\"\"\n",
    "    total_path = [current]\n",
    "    while current in cameFrom.keys():\n",
    "        # Add where the current node came from to the start of the list\n",
    "        total_path.insert(0, cameFrom[current]) \n",
    "        current=cameFrom[current]\n",
    "        \n",
    "#    print(total_path)\n",
    "    return total_path\n",
    "\n",
    "def A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\", num_cases_x=num_cases_x, num_cases_y=num_cases_y):\n",
    "    \"\"\"\n",
    "    A* for 2D occupancy grid. Finds a path from start to goal.\n",
    "    h is the heuristic function. h(n) estimates the cost to reach goal from node n.\n",
    "    :param start: start node (x, y)\n",
    "    :param goal_m: goal node (x, y)\n",
    "    :param occupancy_grid: the grid map\n",
    "    :param movement: select between 4-connectivity ('4N') and 8-connectivity ('8N', default)\n",
    "    :return: a tuple that contains: (the resulting path in meters, the resulting path in data array indices)\n",
    "    \"\"\"\n",
    "    # -----------------------------------------\n",
    "    # DO NOT EDIT THIS PORTION OF CODE\n",
    "    # -----------------------------------------\n",
    "    # Check if the start and goal are within the boundaries of the map\n",
    "  #  for point in [start, goal]: \n",
    "  #      for coord in point:\n",
    "   #         print('coord',coord)\n",
    "   #         assert coord>=0 and coord<=num_cases_x, \"start or end goal not contained in the map\"\n",
    "  #          assert coord>=0 and coord<=num_cases_y, \"start or end goal not contained in the map\"\n",
    "   # \n",
    "    # Check if the start and goal are within the boundaries of the map\n",
    "    for point in [start, goal]:\n",
    "        x_coord, y_coord = point \n",
    "\n",
    "        assert 0 <= x_coord < num_cases_x, \"X-coordinate of start or end goal not contained in the map\"\n",
    "        assert 0 <= y_coord < num_cases_y, \"Y-coordinate of start or end goal not contained in the map\"\n",
    "    \n",
    "    # check if start and goal nodes correspond to free spaces\n",
    "    if occupancy_grid[start[0], start[1]]:\n",
    "        raise Exception('Start node is not traversable')\n",
    "\n",
    "    if occupancy_grid[goal[0], goal[1]]:\n",
    "        raise Exception('Goal node is not traversable')\n",
    "    \n",
    "    # get the possible movements corresponding to the selected connectivity\n",
    "    if movement_type == '4N':\n",
    "        movements = _get_movements_4n()\n",
    "    elif movement_type == '8N':\n",
    "        movements = _get_movements_8n()\n",
    "    else:\n",
    "        raise ValueError('Unknown movement')\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # A* Algorithm implementation - feel free to change the structure / use another pseudo-code\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # The set of visited nodes that need to be (re-)expanded, i.e. for which the neighbors need to be explored\n",
    "    # Initially, only the start node is known.\n",
    "    openSet = [start]\n",
    "    \n",
    "    # The set of visited nodes that no longer need to be expanded.\n",
    "    closedSet = []\n",
    "\n",
    "    # For node n, cameFrom[n] is the node immediately preceding it on the cheapest path from start to n currently known.\n",
    "    cameFrom = dict()\n",
    "\n",
    "    # For node n, gScore[n] is the cost of the cheapest path from start to n currently known.\n",
    "    gScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    gScore[start] = 0\n",
    "\n",
    "    # For node n, fScore[n] := gScore[n] + h(n). map with default value of Infinity\n",
    "    fScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    fScore[start] = h[start]\n",
    "\n",
    "    # while there are still elements to investigate\n",
    "    while openSet != []:\n",
    "        \n",
    "        #the node in openSet having the lowest fScore[] value\n",
    "        fScore_openSet = {key:val for (key,val) in fScore.items() if key in openSet}\n",
    "        current = min(fScore_openSet, key=fScore_openSet.get)\n",
    "        del fScore_openSet\n",
    "        \n",
    "        #If the goal is reached, reconstruct and return the obtained path\n",
    "        if current == goal:\n",
    "#            print(closedSet)\n",
    "            return reconstruct_path(cameFrom, current), closedSet\n",
    "\n",
    "        openSet.remove(current)\n",
    "        closedSet.append(current)\n",
    "        \n",
    "        #for each neighbor of current:\n",
    "        for dx, dy, deltacost in movements:\n",
    "            \n",
    "            neighbor = (current[0]+dx, current[1]+dy)\n",
    "            \n",
    "            # if the node is not in the map, skip\n",
    "            if (neighbor[0] >= occupancy_grid.shape[0]) or (neighbor[1] >= occupancy_grid.shape[1]) or (neighbor[0] < 0) or (neighbor[1] < 0):\n",
    "                continue\n",
    "            \n",
    "            # if the node is occupied or has already been visited, skip\n",
    "            if (occupancy_grid[neighbor[0], neighbor[1]]) or (neighbor in closedSet): \n",
    "                continue\n",
    "                \n",
    "            # d(current,neighbor) is the weight of the edge from current to neighbor\n",
    "            # tentative_gScore is the distance from start to the neighbor through current\n",
    "            tentative_gScore = gScore[current] + deltacost\n",
    "            \n",
    "            if neighbor not in openSet:\n",
    "                openSet.append(neighbor)\n",
    "                \n",
    "            if tentative_gScore < gScore[neighbor]:\n",
    "                # This path to neighbor is better than any previous one. Record it!\n",
    "                cameFrom[neighbor] = current\n",
    "                gScore[neighbor] = tentative_gScore\n",
    "                fScore[neighbor] = gScore[neighbor] + h[neighbor]\n",
    "\n",
    "    # Open set is empty but goal was never reached\n",
    "    print(\"No path found to goal\")\n",
    "    return [], closedSet\n",
    "\n",
    "def truncate_coordinate(center_matrix, X, Y):\n",
    "    \n",
    "    threshold_x = 55\n",
    "    threshold_y = 55\n",
    "    num_cases_y, num_cases_x = center_matrix.shape[:2]  # Obtention des dimensions de la matrice\n",
    "\n",
    "    for i in range(num_cases_y):\n",
    "        for j in range(num_cases_x):\n",
    "            diff_x = abs(center_matrix[i, j][0] - X)\n",
    "            diff_y = abs(center_matrix[i, j][1] - Y)\n",
    "\n",
    "            if diff_x <= threshold_x and diff_y <= threshold_y:\n",
    "                x_out, y_out = j, i  \n",
    "  #  for i in range(num_cases_y):\n",
    "   #     for j in range(num_cases_x):\n",
    "    #        \n",
    "     #       if center_matrix[i,j][0] - X <= threshold_x and center_matrix[i,j][1] - Y <= threshold_y:\n",
    "      #          x_out = j\n",
    "       #         y_out = i\n",
    "    \n",
    "#    if y_out == 0: y_out = 5\n",
    " #   if y_out == 1: y_out = 4\n",
    "  #  if y_out == 2: y_out = 3\n",
    "   # if y_out == 3: y_out = 2\n",
    "    #if y_out == 4: y_out = 1\n",
    "    #if y_out == 5: y_out = 0\n",
    "  \n",
    "    return(x_out,y_out)\n",
    "\n",
    "def symetrie_lignes(matrix):\n",
    " \n",
    "    copy_matrix = copy.deepcopy(matrix)\n",
    "    matrix[0][:] = copy_matrix[5][:]\n",
    "    matrix[1][:] = copy_matrix[4][:]\n",
    "    matrix[2][:] = copy_matrix[3][:]\n",
    "    matrix[3][:] = copy_matrix[2][:]\n",
    "    matrix[4][:] = copy_matrix[1][:]\n",
    "    matrix[5][:] = copy_matrix[0][:]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe9abe0-7939-44d6-b6c3-6996945398bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motor_set_speed(left_speed, right_speed,node):\n",
    "    aw(node.set_variables(motors(left_speed,right_speed)))\n",
    "    \n",
    "def motors(left_speed, right_speed):\n",
    "    return {\n",
    "        \"motor.left.target\": [left_speed],\n",
    "        \"motor.right.target\": [right_speed],\n",
    "    }\n",
    "def check_obstacle_state(obst):\n",
    "    \"\"\"Checks which next state the robot should go in\n",
    "        0: saw an obstacle\n",
    "        1: normal state\n",
    "        2: corrects trajectory after avoiding obstacle\n",
    "    \"\"\"\n",
    "\n",
    "    global saw_obstacle\n",
    "\n",
    "    obstThr = 500\n",
    "    if all(elements < obstThr for elements in obst):\n",
    "        if saw_obstacle:\n",
    "            # Ici, l'obstacle a été contourné\n",
    "            saw_obstacle = False\n",
    "            return 2  # État après contournement\n",
    "        else:\n",
    "            return 1  # État initial, pas d'obstacle\n",
    "    else:\n",
    "        saw_obstacle = True\n",
    "        return 0  # Obstacle détecté\n",
    "\n",
    "\n",
    "def local_navi(obst):\n",
    "\n",
    "    speed0 = 50      \n",
    "    obstSpeedGain = [6, 4, -2, -6, -8]\n",
    "    spLeft = speed0\n",
    "    spRight = speed0\n",
    "\n",
    "    for i in range(5):\n",
    "        spLeft += obst[i] * obstSpeedGain[i] // 100\n",
    "        spRight += obst[i] * obstSpeedGain[4 - i] // 100\n",
    "\n",
    "    return spLeft, spRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cae95fee-6bcb-4fc0-9510-29c30b220361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_robot_rect(x_a,y_a,x_t,y_t):\n",
    "    global motor_left_target, motor_right_target,distance\n",
    "    x_a = x_a/100\n",
    "    y_a = y_a/100\n",
    "    x_t = x_t/100\n",
    "    y_t = y_t/100\n",
    "    distance = calculate_distance(x_a, y_a, x_t, y_t)\n",
    "    print('new function move')\n",
    "    time_distance = distance*1.5\n",
    "    print('time distance', time_distance)\n",
    "    v = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(100)],\n",
    "    }\n",
    "    aw(node.set_variables(v))\n",
    "    time.sleep(time_distance)\n",
    "    filter_call(100, 100, time_distance)\n",
    "    v_stop = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "            \"motor.right.target\": [int(0)],\n",
    "        }\n",
    "    aw(node.set_variables(v_stop))\n",
    "#LOCAL NAVIGATION CHECK\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a5d254-0c54-4f18-b56f-31bcad9f6120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_robot_angle(angle):\n",
    "    \"\"\"\n",
    "    teta: ,mode, x_a, y_a, x_t, y_t\n",
    "    \"\"\"\n",
    "    global motor_left_target, motor_right_target,move_list,count, ekf\n",
    "    \n",
    "    if angle < 0 :\n",
    "        angle = -angle\n",
    "        time_rotation = (4.95 * angle) / 180\n",
    "        v = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(-100)],\n",
    "    }\n",
    "        aw(node.set_variables(v))\n",
    "        time.sleep(time_rotation)\n",
    "        filter_call(-100, 100, time_rotation)\n",
    "        \n",
    "    else:\n",
    "        time_rotation = (4.95 * angle) / 180\n",
    "        if time_rotation == 0 :\n",
    "            v_reverse = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(100)],\n",
    "            }\n",
    "            aw(node.set_variables(v_reverse))\n",
    "            time.sleep(time_rotation)\n",
    "            filter_call(100, 100, time_rotation)\n",
    "        else :\n",
    "            v_reverse = {\n",
    "                \"motor.left.target\": [int(-100)],\n",
    "                \"motor.right.target\": [int(100)],\n",
    "            }\n",
    "            aw(node.set_variables(v_reverse))\n",
    "            time.sleep(time_rotation)\n",
    "            filter_call(100, -100, time_rotation)\n",
    "        \n",
    "    v_stop = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "            \"motor.right.target\": [int(0)],\n",
    "        }\n",
    "    aw(node.set_variables(v_stop))\n",
    "    print(\"stopped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e057910-ff49-42ff-8228-b6b23f662f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction_1(teta_a,x_a,y_a,x_t,y_t, teta_t):\n",
    "#   global x_a,y_a,teta_a,x_t,y_t,teta_t\n",
    "    print(\"correction 1\")\n",
    "\n",
    "    v = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "    }\n",
    "    aw(node.set_variables(v))\n",
    "    #We need to go from actuel position to theorical position\n",
    "    #rotate_robot_angle(teta_a,0,x_a,y_a,x_t,y_t)\n",
    "    #move_robot_rect(x_a,y_a,x_t,y_t)\n",
    "    print(\"correction 1 angle\", teta_a-teta_t)\n",
    "    rotate_robot_angle(teta_a - teta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6af2cd99-1690-4f90-b0e3-02e0b487ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction_3(x_a,y_a,teta_a,x_t,y_t,teta_t):\n",
    "    print(\"correction 3\")\n",
    "    teta = calculate_angle_degrees(x_a, y_a, x_t, y_t)\n",
    "    angle1 = teta - teta_a\n",
    "    v = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "    }\n",
    "    aw(node.set_variables(v))\n",
    "    #We need to go from actuel position to theorical position\n",
    "    rotate_robot_angle(angle1)\n",
    "    move_robot_rect(x_a//100,y_a//100,x_t//100,y_t//100)\n",
    "    angle2 = teta_t - teta\n",
    "    rotate_robot_angle(angle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b3e3c79-b554-425e-ada2-2e98274c6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(x_a, y_a, teta_a, x_t,y_t,teta_t):\n",
    "    \"\"\"Controller that decides what correction to make depending on the distance and angle of estimated\"\"\"\n",
    "    dist = calculate_distance(x_a, y_a, x_t, y_t)\n",
    "    print(\"dist\", dist)\n",
    "    if (dist>100):\n",
    "        print(\"xa ya\", x_a, y_a)\n",
    "        print(\"xt yt\", x_t, y_t)\n",
    "        correction_3(x_a,y_a,teta_a,x_t,y_t,teta_t)\n",
    "        return\n",
    "    if (abs(teta_a-teta_t)>5):\n",
    "        correction_1(teta_a, x_a,y_a,x_t,y_t,teta_t)\n",
    "        return\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1570848a-4770-47d3-bdb0-c6b6912af1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "obstacle_state = 1\n",
    "saw_obstacle = False\n",
    "def rotate_robot():\n",
    "    global x1 ,y1 ,x2 ,y2, motor_left_target, motor_right_target,angle,move_list,count\n",
    "    angle = calculate_angle_degrees(x1, y1, x2, y2)\n",
    "#    print('count =', count)\n",
    "    \n",
    "    if move_list[count] == angle :\n",
    "        angle = 0\n",
    "    else :\n",
    "        move_list[count+1] = angle\n",
    "        angle = angle - move_list[count]\n",
    "        count = count+1\n",
    "    print(move_list)\n",
    "    \n",
    "    if angle < 0 :\n",
    "        angle = -angle\n",
    "        time_rotation = (4.95 * angle) / 180\n",
    "        v = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(-100)],\n",
    "    }\n",
    "        aw(node.set_variables(v))\n",
    "        time.sleep(time_rotation)\n",
    "        filter_call(-100, 100, time_rotation)\n",
    "    else:\n",
    "        time_rotation = (4.95 * angle) / 180\n",
    "        if time_rotation == 0 :\n",
    "            v_reverse = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(100)],\n",
    "            }\n",
    "            aw(node.set_variables(v_reverse))\n",
    "            time.sleep(time_rotation)\n",
    "            filter_call(100, 100, time_rotation)\n",
    "        else :\n",
    "            v_reverse = {\n",
    "                \"motor.left.target\": [int(-100)],\n",
    "                \"motor.right.target\": [int(100)],\n",
    "            }\n",
    "            aw(node.set_variables(v_reverse))\n",
    "            time.sleep(time_rotation)\n",
    "            filter_call(100, -100, time_rotation)\n",
    "    v_stop = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "            \"motor.right.target\": [int(0)],\n",
    "        }\n",
    "    aw(node.set_variables(v_stop))\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "def move_robot():\n",
    "    global x1 ,y1 ,x2 ,y2, motor_left_target, motor_right_target,distance\n",
    "    distance = calculate_distance(x1, y1, x2, y2)\n",
    "    time_distance = distance*1.5 ################J'AI CHANGE CA###############################\n",
    "    v = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(100)],\n",
    "        }\n",
    "    aw(node.set_variables(v))\n",
    "    time.sleep(time_distance)\n",
    "    filter_call(100, 100, time_distance)\n",
    "    v_stop = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "            \"motor.right.target\": [int(0)],\n",
    "        }\n",
    "    aw(node.set_variables(v_stop))\n",
    "#LOCAL NAVIGATION CHECK\n",
    "    \n",
    "\n",
    "\n",
    "def A_star_move():\n",
    "    global x1, y1, x2, y2, motor_left_target, motor_right_target, move_list,obstacle_state,prox_ground_delta, prox_horizontal,obst, obstThrH, obstThrL, obstSpeedGain, speed0, speedGain, robot_state, saw_obstacl, ekf\n",
    "    \n",
    "    while True :\n",
    "        if obstacle_state == 1 :\n",
    "            data, center_matrix, x_end, y_end, robot_state, result_image = info_robot_cam()\n",
    "\n",
    "            # initialise filter\n",
    "            if ekf == None:\n",
    "                ekf = EKF(0.1, np.array([robot_state.x, robot_state.y, robot_state.angle]), np.zeros(2))\n",
    "                print(\"angle filtre\", robot_state.angle)\n",
    "            fig, ax = create_empty_plot(num_cases_x,num_cases_y)\n",
    "             # Creating the occupancy grid\n",
    "            center_matrix_array = np.array(center_matrix)\n",
    "            center_matrix_array = symetrie_lignes(center_matrix_array)\n",
    "                \n",
    "            cmap = colors.ListedColormap(['white', 'red']) # Select the colors with which to display obstacles and free cells    \n",
    "                \n",
    "            # Converting the random values into occupied and free cells\n",
    "            limit = 0\n",
    "            occupancy_grid = data.copy()\n",
    "    \n",
    "            \n",
    "            occupancy_grid[data>limit] = 1\n",
    "            occupancy_grid[data<=limit] = 0\n",
    "            occupancy_grid= occupancy_grid.transpose()\n",
    "    \n",
    "            # Displaying the map\n",
    "            ax.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "            plt.title(\"Map : free cells in white, occupied cells in red\");\n",
    "            \n",
    "\n",
    "            # Run the A* algorithm\n",
    "             \n",
    "            #ici on fait le check infocam/filtre/pid, car la local nav est une boucle\n",
    "            start_x = robot_state.x\n",
    "            start_y = robot_state.y\n",
    "            start = truncate_coordinate(center_matrix_array,robot_state.x, robot_state.y)\n",
    "            goal = truncate_coordinate(center_matrix_array, x_end, y_end)\n",
    "            \n",
    "            print('goal',goal)\n",
    "            print('start',start)\n",
    "                \n",
    "            x,y = np.mgrid[0:num_cases_x:1, 0:num_cases_y:1]\n",
    "            pos = np.empty(x.shape + (2,))\n",
    "            pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "            pos = np.reshape(pos, (x.shape[0]*x.shape[1], 2))\n",
    "            coords = list([(int(x[0]), int(x[1])) for x in pos])\n",
    "            h = np.linalg.norm(pos - goal, axis=-1)\n",
    "            h = dict(zip(coords, h))\n",
    "#            print(occupancy_grid)\n",
    "            path, visitedNodes = A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\")\n",
    "            path = np.array(path).reshape(-1, 2).transpose()\n",
    "            visitedNodes = np.array(visitedNodes).reshape(-1, 2).transpose()\n",
    "\n",
    "            # Displaying the map\n",
    "            fig_astar, ax_astar = create_empty_plot(num_cases_x,num_cases_y)\n",
    "            ax_astar.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "        \n",
    "            # Plot the best path found and the list of visited nodes\n",
    "            ax_astar.scatter(visitedNodes[0], visitedNodes[1], marker=\"o\", color = 'orange');\n",
    "            ax_astar.plot(path[0], path[1], marker=\"o\", color = 'blue');\n",
    "            ax_astar.scatter(start[0], start[1], marker=\"o\", color = 'green', s=200);\n",
    "            ax_astar.scatter(goal[0], goal[1], marker=\"o\", color = 'purple', s=200);\n",
    "            \n",
    "            # Displaying the map\n",
    "            fig_astar, ax_astar = create_empty_plot(num_cases_x,num_cases_y)\n",
    "            ax_astar.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "                \n",
    "            # Plot the best path found and the list of visited nodes\n",
    "            ax_astar.scatter(visitedNodes[0], visitedNodes[1], marker=\"o\", color = 'orange');\n",
    "            ax_astar.plot(path[0], path[1], marker=\"o\", color = 'blue');\n",
    "            ax_astar.scatter(start[0], start[1], marker=\"o\", color = 'green', s=200);\n",
    "            ax_astar.scatter(goal[0], goal[1], marker=\"o\", color = 'purple', s=200);\n",
    "            \n",
    "            print(len(path))\n",
    "            move_list = [0] * len(path[0])\n",
    "            print(\"move list\", move_list)\n",
    "            print(\"path\", path)\n",
    "            for i in range(len(path[1])-1):\n",
    "                x1 = path[0][i]\n",
    "                x2 = path[0][i+1]\n",
    "                y1 = path[1][i]\n",
    "                y2 = path[1][i]\n",
    "                if (i+2<len(path[1])):\n",
    "                    x3 = path[0][i+2]\n",
    "                    y3 = path[1][i+2]\n",
    "\n",
    "                _, _, _, _, robot_state, _ = info_robot_cam()\n",
    "                print(\"x1 y1\", x1, y1)\n",
    "                print('robot state x', robot_state.x)\n",
    "                print(\"robot state y\", robot_state.y)\n",
    "                print('real x', center_matrix_array[y1][x1][0])\n",
    "                print('real y', center_matrix_array[y1][x1][1])\n",
    "                print('angle actuel', robot_state.angle)\n",
    "                print('angle theorique', move_list[count])\n",
    "                x_filter,y_filter,angle_filter = ekf.get_pos()\n",
    "                print('x filtre', x_filter)\n",
    "                print('y filtre', y_filter)\n",
    "                print('angle filtre', angle_filter)\n",
    "                correction(x_filter, y_filter, angle_filter, center_matrix_array[y1][x1][0],center_matrix_array[y1][x1][1], move_list[count])\n",
    "                rotate_robot()\n",
    "                # data, center_matrix, x_end, y_end, robot_state, result_image = info_robot_cam()\n",
    "                for j in range(3):\n",
    "                \n",
    "                    move_robot()\n",
    "                    aw(node.wait_for_variables({\"prox.horizontal\"}))\n",
    "                    obst = (list(node.v.prox.horizontal))\n",
    "                    obstacle_state = check_obstacle_state(obst)\n",
    "#                    print(obstacle_state)\n",
    "                    while obstacle_state == 0: \n",
    "                        print(\"obstacle\")\n",
    "                        #local navigation\n",
    "                        update_time()\n",
    "                        for k in range(8):\n",
    "                            leftSpeed, rightSpeed = local_navi(obst)\n",
    "                            motor_set_speed(leftSpeed, rightSpeed, node)\n",
    "                            filter_call(rightSpeed, leftSpeed, update_time())\n",
    "                        motor_set_speed(100,100,node)\n",
    "                        time_sleep = 1.5\n",
    "                        time.sleep(time_sleep)\n",
    "                        filter_call(100, 100, time_sleep)\n",
    " #                       obstacle_state = 2\n",
    "                        obstacle_state = check_obstacle_state(obst)\n",
    " #                      print(obstacle_state)\n",
    "                    if obstacle_state == 2:\n",
    "                        print(\"state 2\")\n",
    "                        x_f, y_f, angle_f = ekf.get_pos()\n",
    "                        #data, center_matrix, x_end, y_end, robot_state, result_image = info_robot_cam()\n",
    "                        correction(x_f,y_f, angle_f, center_matrix_array[y3][x3][0],center_matrix_array[y3][x3][1], move_list[count])\n",
    "                        obstacle_state = 1\n",
    "                        break\n",
    "        if abs(robot_state.x - x_end) < 55 and abs(robot_state.y - y_end) < 55 :\n",
    "            break\n",
    "#mettre une condition, si robot sur case arrivée, on sort de ce while True avec un break\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b854348-6e19-47b2-b801-f403691b688a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle filtre -0.0\n",
      "goal (7, 5)\n",
      "start (4, 3)\n",
      "2\n",
      "move list [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "path [[4 3 3 3 4 5 6 7]\n",
      " [3 3 4 5 5 5 5 5]]\n",
      "x1 y1 4 3\n",
      "robot state x 700\n",
      "robot state y 326\n",
      "real x 695\n",
      "real y 330\n",
      "angle actuel -0.0\n",
      "angle theorique 0\n",
      "x filtre 700.0\n",
      "y filtre 326.0\n",
      "angle filtre 0.0\n",
      "dist 6.4031242374328485\n",
      "[0, 180.0, 0, 0, 0, 0, 0, 0]\n",
      "x1 y1 3 3\n",
      "robot state x 567\n",
      "robot state y 429\n",
      "real x 588\n",
      "real y 327\n",
      "angle actuel -137.72631099390625\n",
      "angle theorique 180.0\n",
      "x filtre 565\n",
      "y filtre 459\n",
      "angle filtre -138\n",
      "dist 104.1393297462587\n",
      "xa ya 567 429\n",
      "xt yt 588 327\n",
      "correction 3\n",
      "stopped\n",
      "new function move\n",
      "time distance 0.015000000000000003\n",
      "stopped\n",
      "[0, 180.0, 0.0, 0, 0, 0, 0, 0]\n",
      "x1 y1 3 4\n",
      "robot state x 607\n",
      "robot state y 405\n",
      "real x 590\n",
      "real y 228\n",
      "angle actuel 30.96375653207352\n",
      "angle theorique 0.0\n",
      "x filtre 603\n",
      "y filtre 407\n",
      "angle filtre 30\n",
      "dist 177.81451009408653\n",
      "xa ya 607 405\n",
      "xt yt 590 228\n",
      "correction 3\n",
      "stopped\n",
      "new function move\n",
      "time distance 0.03354101966249684\n",
      "stopped\n",
      "[0, 180.0, 0.0, 0, 0, 0, 0, 0]\n",
      "x1 y1 3 5\n",
      "robot state x 624\n",
      "robot state y 421\n",
      "real x 593\n",
      "real y 129\n",
      "angle actuel 145.99326779387974\n",
      "angle theorique 0.0\n",
      "x filtre 620\n",
      "y filtre 421\n",
      "angle filtre 144\n",
      "dist 293.64093720052045\n",
      "xa ya 624 421\n",
      "xt yt 593 129\n",
      "correction 3\n",
      "stopped\n",
      "new function move\n",
      "time distance 0.04743416490252569\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb Cellule 22\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m A_star_move()\n",
      "\u001b[1;32m/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb Cellule 22\u001b[0m line \u001b[0;36mA_star_move\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39my filtre\u001b[39m\u001b[39m'\u001b[39m, y_filter)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mangle filtre\u001b[39m\u001b[39m'\u001b[39m, angle_filter)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m correction(robot_state\u001b[39m.\u001b[39;49mx, robot_state\u001b[39m.\u001b[39;49my, robot_state\u001b[39m.\u001b[39;49mangle, center_matrix_array[y1][x1][\u001b[39m0\u001b[39;49m],center_matrix_array[y1][x1][\u001b[39m1\u001b[39;49m], move_list[count])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m rotate_robot()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m \u001b[39m# data, center_matrix, x_end, y_end, robot_state, result_image = info_robot_cam()\u001b[39;00m\n",
      "\u001b[1;32m/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb Cellule 22\u001b[0m line \u001b[0;36mcorrection\u001b[0;34m(x_a, y_a, teta_a, x_t, y_t, teta_t)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mxa ya\u001b[39m\u001b[39m\"\u001b[39m, x_a, y_a)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mxt yt\u001b[39m\u001b[39m\"\u001b[39m, x_t, y_t)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     correction_3(x_a,y_a,teta_a,x_t,y_t,teta_t)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mabs\u001b[39m(teta_a\u001b[39m-\u001b[39mteta_t)\u001b[39m>\u001b[39m\u001b[39m5\u001b[39m):\n",
      "\u001b[1;32m/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb Cellule 22\u001b[0m line \u001b[0;36mcorrection_3\u001b[0;34m(x_a, y_a, teta_a, x_t, y_t, teta_t)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m move_robot_rect(x_a\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m,y_a\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m,x_t\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m,y_t\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m angle2 \u001b[39m=\u001b[39m teta_t \u001b[39m-\u001b[39m teta\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m rotate_robot_angle(angle2)\n",
      "\u001b[1;32m/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb Cellule 22\u001b[0m line \u001b[0;36mrotate_robot_angle\u001b[0;34m(angle)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         v_reverse \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmotor.left.target\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39mint\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmotor.right.target\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39mint\u001b[39m(\u001b[39m100\u001b[39m)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         aw(node\u001b[39m.\u001b[39mset_variables(v_reverse))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         time\u001b[39m.\u001b[39;49msleep(time_rotation)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         filter_call(\u001b[39m100\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m, time_rotation)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m v_stop \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmotor.left.target\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39mint\u001b[39m(\u001b[39m0\u001b[39m)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmotor.right.target\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39mint\u001b[39m(\u001b[39m0\u001b[39m)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/merge_control_CV_global_local.ipynb#X26sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_star_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935816d9-a025-4f08-ad4d-9c56ec83a637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161.32791622619865\n"
     ]
    }
   ],
   "source": [
    "data, center_matrix, x_end, y_end, robot_state, result_image = info_robot_cam()\n",
    "print(robot_state.angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885761e-7fd0-463b-9cf7-3cdd343bffd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (3058949132.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [23]\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "   \n",
    "cv2.imshow('Live Footage', result_image)\n",
    "#if you click on any key it stops the program\n",
    "if cv2.waitKey(1) == 27:\n",
    "    break\n",
    "            \n",
    "            # Wait until a second has passed since the start of the iteration\n",
    "while time.time() - start_time < 1:\n",
    "    time.sleep(0.01) \n",
    "else:\n",
    "    break\n",
    "\n",
    "# Release the camera and close the window\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(1, 5):\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
