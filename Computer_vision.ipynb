{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab62e39-a0e4-4b1c-aabe-0b9a1fe546ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "import IPython.display as Disp\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914f008-3e57-4ec3-8831-a94391c8f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global initialization \n",
    "x_end = y_end=0\n",
    "# All coordonates are initialized to 0\n",
    "class RobotState:\n",
    "    def __init__(self, x=0, y=0, r=0, angle=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.angle = angle \n",
    "\n",
    "robot_state = RobotState()\n",
    "\n",
    "# size of our environment grid\n",
    "num_cases_x = 8  # horizontal cells (valeur arbitraire ici juste pour que ca marche dans mon exemple) \n",
    "num_cases_y = 6   # vertical cells\n",
    "\n",
    "# Initializing our matrix containing the environment information\n",
    "center_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)] #jsp si c'est comme ca qu'on initialise a zero une matrice\n",
    "state_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)]\n",
    "debug_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)]\n",
    "\n",
    "#camera related initialization \n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "#Lower the resolution\n",
    "cam.set(3, 1280)\n",
    "cam.set(4, 720)\n",
    "\n",
    "# Initialize a variable to store the last time an image was acquired\n",
    "last_image_time = time.time()\n",
    "result, image = cam.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793aef31-e678-4e01-9426-89dc85bd27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(image):\n",
    "    \"\"\"    \n",
    "    Preprocess an image for use in computer vision applications.\n",
    "    \n",
    "    Arguments:\n",
    "    image : The input image to be preprocessed.\n",
    "        \n",
    "    Returns:\n",
    "    filtered_image : The preprocessed image.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale for filtering.\n",
    "    image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply bilateral filtering to reduce noise while preserving edges.\n",
    "    bilateral = cv2.bilateralFilter(image_grey, d=5, sigmaColor=25, sigmaSpace=25)\n",
    "    \n",
    "    # Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) for enhancing details.\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    filtered_image1 = clahe.apply(bilateral)\n",
    "    \n",
    "    # Apply Gaussian blur to further use \n",
    "    filtered_image = cv2.GaussianBlur(filtered_image1, (5, 5), 0)\n",
    "    \n",
    "    return filtered_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc612ab-a5cc-4290-8a1e-a9fa0a0e31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_info(keypoints, result_image, robot_state):\n",
    "    \"\"\"\n",
    "    Update the essential information to describe the state of the robot.\n",
    "    \n",
    "    Arguments:\n",
    "        keypoints: Detected keypoints representing potential robot positions.\n",
    "        result_image: The image on which to draw the keypoints.\n",
    "        robot_state: An instance of RobotState containing the coordinates and angle of the robot.\n",
    "        \n",
    "    Returns:\n",
    "        robot_state: The updated RobotState instance.\n",
    "    \"\"\"\n",
    "   \n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = True\n",
    "    params.minCircularity = 0.8\n",
    "    params.maxCircularity = 1\n",
    "        \n",
    "    # Filter by color\n",
    "    params.filterByColor = True\n",
    "\n",
    "    x=y=r=x_big=y_big=r_big=x_small=y_small=r_small=0\n",
    "\n",
    "    # Minimum circle radius we want to detect\n",
    "    small_circle_radius_threshold_max = 14 #(le gros il fais 25 et le petit 18 pour la resolution normale)\n",
    "    small_circle_radius_threshold_min = 5\n",
    "    # Check if any blobs (potential circles) were detected\n",
    "    if keypoints:\n",
    "#---- \n",
    "#     print(f\"{len(keypoints)} blobs detected.\")\n",
    "#----                 \n",
    "        # Draw circles on the original image\n",
    "        for keypoint in keypoints:\n",
    "            x = int(keypoint.pt[0])\n",
    "            y = int(keypoint.pt[1])\n",
    "            r = int(keypoint.size / 2)\n",
    "\n",
    "            if small_circle_radius_threshold_min < r < small_circle_radius_threshold_max:\n",
    "                x_small = x\n",
    "                y_small = y\n",
    "                r_small = r\n",
    "            elif r > small_circle_radius_threshold_max:\n",
    "                x_big = x\n",
    "                y_big = y\n",
    "                r_big = r\n",
    "#----        \n",
    "        # print(robot_state.x,robot_state.y,robot_state.r)\n",
    "        print('r_small =', r_small)\n",
    "        print('r_big =', r_big)\n",
    "        cv2.circle(result_image, (x_big, y_big), r_big, (255, 0, 255), 8) # just to check on the video\n",
    "        cv2.circle(result_image, (x_small, y_small), r_small, (255, 0, 255), 8) # just to check on the video\n",
    "\n",
    "           # print(r)\n",
    "#----\n",
    "        robot_state.x = x_big\n",
    "        robot_state.y = y_big\n",
    "        #Robot orientation = angle between the trajectorie of the robot and the vertical axis\n",
    "        Vect_dir = (x_small - x_big , y_small - y_big)\n",
    "        Vertical = (0, 1)\n",
    "            \n",
    "        dot_product = Vect_dir[0] * Vertical[0] + Vect_dir[1] * Vertical[1]\n",
    "            \n",
    "        magnitude_dir = math.sqrt(Vect_dir[0]**2 + Vect_dir[1]**2)\n",
    "        magnitude_V = math.sqrt(Vertical[0]**2 + Vertical[1]**2)\n",
    "                \n",
    "        # Angle in radiants\n",
    "        if magnitude_dir != 0 and magnitude_V != 0:\n",
    "            angle_rad = math.acos(dot_product / (magnitude_dir * magnitude_V))\n",
    "        else:\n",
    "            angle_rad = 0\n",
    "        # Convertion in degrees\n",
    "        robot_state.angle = math.degrees(angle_rad)\n",
    "# ---\n",
    "#print(robot_state.angle)\n",
    "#---\n",
    "    return robot_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae3dfa-60c3-4646-80a8-3bfa5ce06824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_setting1(filtered_image,center_matrix,state_matrix,result_image):\n",
    "    \"\"\"\n",
    "    Initializes the grid and updates both the center_matrix and state_matrix with the environment information.\n",
    "    \n",
    "    Arguments:\n",
    "        filtered_image: The image after applying filters, used for contour detection.\n",
    "        center_matrix: A matrix representing the centers of each grid cell.\n",
    "        state_matrix: A matrix representing the state (BLACK, WHITE, ROBOT, TARGET) of each grid cell.\n",
    "        \n",
    "    Returns:\n",
    "        center_matrix, state_matrix.\n",
    "    \"\"\"\n",
    "    #local constant\n",
    "    BLACK = 1\n",
    "    WHITE = 2\n",
    "    ROBOT  = 3\n",
    "    TARGET = 4\n",
    "\n",
    "    black_threshold = 30\n",
    "    white_threshold = 110 \n",
    "    red_threshold_inf = 65\n",
    "    red_threshold_sup = 105\n",
    "    robot_pos_delta_x = 60\n",
    "    robot_pos_delta_y = 80  \n",
    "\n",
    "    min_area_threshold = 75000\n",
    "    # Contour Detection with the Canny filter\n",
    "    countours_image = cv2.Canny(filtered_image, 50, 150, apertureSize=3)\n",
    "    \n",
    "    contours, _ = cv2.findContours(countours_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # grid initializatoin, these points are used to know the grid size\n",
    "    right_pt = left_pt = top_pt = bottom_pt =  [0,0]\n",
    "\n",
    "    center_matrix_prev = copy.deepcopy(center_matrix)\n",
    "    state_matrix_prev = copy.deepcopy(state_matrix)\n",
    "\n",
    "    if contours:\n",
    "        for contour in contours:\n",
    "            # Calculate contour area\n",
    "            area = cv2.contourArea(contour)\n",
    "\n",
    "            # Filter out contours that are too small or too large\n",
    "            if area > min_area_threshold: \n",
    "                #Finding the largest contour (the grid contour)\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "                # Draw the largest contour and centroid\n",
    "                cv2.drawContours(result_image, [largest_contour], -1, (0, 255, 0), 2)\n",
    "                    \n",
    "                # Finding the extrem points\n",
    "                left_pt = tuple(largest_contour[largest_contour[:, :, 0].argmin()][0])\n",
    "                right_pt = tuple(largest_contour[largest_contour[:, :, 0].argmax()][0])\n",
    "                top_pt = tuple(largest_contour[largest_contour[:, :, 1].argmin()][0])\n",
    "                bottom_pt = tuple(largest_contour[largest_contour[:, :, 1].argmax()][0])\n",
    "#----              \n",
    "        cv2.circle(result_image, left_pt, 20, (255, 0, 0), -1)\n",
    "        cv2.circle(result_image, right_pt, 20, (255, 0, 0), -1)\n",
    "        cv2.circle(result_image, top_pt, 20, (255, 0, 0), -1)\n",
    "        cv2.circle(result_image, bottom_pt, 20, (255, 0, 0), -1)\n",
    "\n",
    "        #Debugging only\n",
    "#        print(f\"Leftmost: {left_pt}\")\n",
    "#        print(f\"Rightmost: {right_pt}\")\n",
    "#        print(f\"Topmost: {top_pt}\")\n",
    "#        print(f\"Bottommost: {bottom_pt}\")\n",
    "#----         \n",
    "        # Single cell size computing \n",
    "        case_width = (right_pt[0] - left_pt[0]) // num_cases_x  \n",
    "        case_height = (bottom_pt[1] - top_pt[1]) // num_cases_y\n",
    "        \n",
    "        # Computing the cell center\n",
    "        for i in range(num_cases_y):  \n",
    "            for j in range(num_cases_x): \n",
    "                center_x = left_pt[0] + j * case_width + case_width // 2\n",
    "                center_y = top_pt[1] + i * case_height + case_height // 2\n",
    "                \n",
    "                center_matrix[i][j] = (center_x, center_y)\n",
    "                \n",
    "                #Determine the gray-scale of the center pixel\n",
    "                center_value = filtered_image[center_y, center_x]\n",
    "#----\n",
    "                # Draw a circle to mark the center of each cell\n",
    "                cv2.circle(result_image, (center_x, center_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "                debug_matrix[i][j]=center_value\n",
    "                #print('x: ',center_x-x, ' y: ',center_y-y)\n",
    " #               print(center_value)\n",
    "#----           \n",
    "                #Create the state matrix\n",
    "                if center_value < black_threshold:\n",
    "                    state_matrix[i][j] = BLACK\n",
    "                if center_value > white_threshold:\n",
    "                    state_matrix[i][j] = WHITE\n",
    "                if red_threshold_inf <= center_value <= red_threshold_sup:\n",
    "                    state_matrix[i][j] = TARGET\n",
    "                if 0 <= abs(center_x-robot_state.x) <=  robot_pos_delta_x and 0 <= abs(center_y-robot_state.y) <= robot_pos_delta_y and robot_state.x != 0:\n",
    "                    state_matrix[i][j] = ROBOT\n",
    "    else:\n",
    "        center_matrix = copy.deepcopy(center_matrix_prev)\n",
    "        state_matrix = copy.deepcopy(state_matrix_prev) # comme ca, si on cache on ne detect pas de controu et on garde notre matrice \n",
    "        \n",
    "    return state_matrix, center_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef5207-3407-45aa-b54d-20e775bd5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def grid_setting(filtered_image, center_matrix, state_matrix):\n",
    "    BLACK = 1\n",
    "    WHITE = 0\n",
    "    black_threshold = 30\n",
    "    white_threshold = 110\n",
    "    red_threshold_inf = 65\n",
    "    red_threshold_sup = 105\n",
    "    robot_pos_delta_x = 60\n",
    "    robot_pos_delta_y = 80\n",
    "    min_area_threshold = 75000\n",
    "\n",
    "    top_right = top_left = bottom_right = bottom_left =  [0,0]\n",
    "    x_center = y_center = 0\n",
    "\n",
    "    contours_image = cv2.Canny(filtered_image, 50, 150, apertureSize=3)\n",
    "    contours, _ = cv2.findContours(contours_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    center_matrix_prev = copy.deepcopy(center_matrix)\n",
    "    state_matrix_prev = copy.deepcopy(state_matrix)\n",
    "    \n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour) > min_area_threshold:\n",
    "            peri = cv2.arcLength(largest_contour, True)\n",
    "            approx = cv2.approxPolyDP(largest_contour, 0.02 * peri, True)\n",
    "            \n",
    "            if len(approx) == 4:\n",
    "                cv2.drawContours(result_image, [approx], -1, (0, 255, 0), 2)\n",
    "                ordered_points = order_points(approx.reshape(4, 2))\n",
    "\n",
    "                destination_points = np.array([\n",
    "                    [0, 0],\n",
    "                    [filtered_image.shape[1] - 1, 0],\n",
    "                    [filtered_image.shape[1] - 1, filtered_image.shape[0] - 1],\n",
    "                    [0, filtered_image.shape[0] - 1]\n",
    "                ], dtype=\"float32\")\n",
    "                \n",
    "                matrix = cv2.getPerspectiveTransform(ordered_points, destination_points)\n",
    "                warped_image = cv2.warpPerspective(filtered_image, matrix, (filtered_image.shape[1], filtered_image.shape[0]))\n",
    "                # Right after you calculate the perspective transformation matrix\n",
    "                inverse_matrix = cv2.invert(matrix)[1]\n",
    "                        \n",
    "       # Compute the cell size using the warped image dimensions\n",
    "                case_width = warped_image.shape[1] // num_cases_x\n",
    "                case_height = warped_image.shape[0] // num_cases_y\n",
    "                \n",
    "                          # When mapping the centers back to the original image space\n",
    "                for i in range(num_cases_y):\n",
    "                    for j in range(num_cases_x):\n",
    "                        center_x = j * case_width + case_width // 2\n",
    "                        center_y = i * case_height + case_height // 2\n",
    "                        \n",
    "                        # Convert to a floating-point type\n",
    "                        float_center = np.array([[[center_x, center_y]]], dtype=np.float32)\n",
    "                        \n",
    "                        # Map the centers back to the original image space using the inverse matrix\n",
    "                        original_center = cv2.perspectiveTransform(float_center, inverse_matrix)\n",
    "                        original_center = tuple(original_center[0][0].astype(int))\n",
    "                        \n",
    "                        # Draw the cell center on the original image\n",
    "                        cv2.circle(result_image, original_center, 5, (0, 0, 255), -1)\n",
    "                        \n",
    "                        # Update center_matrix with the mapped center\n",
    "                        center_matrix[i][j] = original_center\n",
    "                        \n",
    "                        x_center, y_center = original_center  # Unpack the tuple\n",
    "                        center_value = filtered_image[y_center, x_center]  # Access the image at the y, x coordinates\n",
    "                        debug_matrix[i][j] = center_value  # Store the grayscale value\n",
    "                        \n",
    "           \n",
    "                        #Create the state matrix\n",
    "                        if center_value < black_threshold:\n",
    "                            state_matrix[i][j] = BLACK\n",
    "                        if center_value > white_threshold:\n",
    "                            state_matrix[i][j] = WHITE\n",
    "                        if red_threshold_inf <= center_value <= red_threshold_sup:\n",
    "                            x_end, y_end = center_matrix[i][j]\n",
    "                            state_matrix[i][j] = WHITE\n",
    "                        \n",
    "    else:\n",
    "        center_matrix = copy.deepcopy(center_matrix_prev)\n",
    "        state_matrix = copy.deepcopy(state_matrix_prev) # comme ca, si on cache on ne detect pas de controu et on garde notre matrice \n",
    "        \n",
    "    return state_matrix, center_matrix, x_end, y_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b854348-6e19-47b2-b801-f403691b688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    start_time = time.time()  # Record the start time\n",
    "\n",
    "    ret, frame = cam.read()\n",
    "    if ret:\n",
    "        result_image = frame.copy()  # Initialiser result_image avec une copie de l'image actuelle\n",
    "\n",
    "        filtered_image = pre_processing(result_image)\n",
    "        plt.imshow(cv2.cvtColor(filtered_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Blob detector parameters for circle detection\n",
    "        params = cv2.SimpleBlobDetector_Params()\n",
    "        \n",
    "        # Create a blob detector with the configured parameters\n",
    "        detector = cv2.SimpleBlobDetector_create(params)\n",
    "        \n",
    "        # Detect blobs in the image\n",
    "        keypoints = detector.detect(filtered_image)\n",
    "\n",
    "        # Update the info about the robot\n",
    "        robot_state = robot_info(keypoints, result_image, robot_state)\n",
    "\n",
    "        state_matrix, center_matrix, x_end, y_end = grid_setting(filtered_image,center_matrix,state_matrix)\n",
    "\n",
    "        #print(x_end,y_end)\n",
    "        print('state_matrix : ')\n",
    "        print(state_matrix[0])\n",
    "        print(state_matrix[1])\n",
    "        print(state_matrix[2])\n",
    "        print(state_matrix[3])\n",
    "        print(state_matrix[4])\n",
    "        print(state_matrix[5])\n",
    "\n",
    "        print('debug_matrix : ')\n",
    "        print(debug_matrix[0])\n",
    "        print(debug_matrix[1])\n",
    "        print(debug_matrix[2])\n",
    "        print(debug_matrix[3])\n",
    "        print(debug_matrix[4])\n",
    "        print(debug_matrix[5])\n",
    "        \n",
    "        cv2.imshow('Live Footage', result_image)\n",
    "\n",
    "        #if you click on any key it stops the program\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "#-----        \n",
    "  #      print(state_matrix)\n",
    "#-----\n",
    "            # Wait until a second has passed since the start of the iteration\n",
    "        while time.time() - start_time < 1:\n",
    "            time.sleep(0.01) \n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the camera and close the window\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(1, 5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e6fc6-fd5d-4141-b9d1-b44695a92175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a1f4f-edf6-4cc7-ab49-6c6478f0d73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
