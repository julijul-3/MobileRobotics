{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab62e39-a0e4-4b1c-aabe-0b9a1fe546ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bokeh in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.3.1)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bokeh) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bokeh) (1.0.7)\n",
      "Requirement already satisfied: numpy>=1.16 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bokeh) (1.24.2)\n",
      "Requirement already satisfied: packaging>=16.8 in /Users/paul_richard/Library/Python/3.11/lib/python/site-packages (from bokeh) (22.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bokeh) (2.1.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bokeh) (9.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bokeh) (6.0.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/paul_richard/Library/Python/3.11/lib/python/site-packages (from bokeh) (6.2)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from bokeh) (2023.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Jinja2>=2.9->bokeh) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/paul_richard/Library/Python/3.11/lib/python/site-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2->bokeh) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2->bokeh) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/paul_richard/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70684718-1daa-4551-8393-57b13538ba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node a13184be-b7ac-45c1-84e9-c4292b7f7ff2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import asyncio\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "import IPython.display as Disp\n",
    "from ipywidgets import widgets\n",
    "\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5914f008-3e57-4ec3-8831-a94391c8f93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 17:51:19.159 Python[10809:492554] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    }
   ],
   "source": [
    "#global initialization \n",
    "x_end = y_end=0\n",
    "# All coordonates are initialized to 0\n",
    "class RobotState:\n",
    "    def __init__(self, x=0, y=0, r=0, angle=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.angle = angle \n",
    "\n",
    "robot_state = RobotState()\n",
    "\n",
    "# size of our environment grid\n",
    "num_cases_x = 8  # horizontal cells (valeur arbitraire ici juste pour que ca marche dans mon exemple) \n",
    "num_cases_y = 6   # vertical cells\n",
    "\n",
    "# Initializing our matrix containing the environment information\n",
    "center_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)] #jsp si c'est comme ca qu'on initialise a zero une matrice\n",
    "state_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)]\n",
    "debug_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)]\n",
    "\n",
    "#camera related initialization \n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "#Lower the resolution\n",
    "cam.set(3, 1280)\n",
    "cam.set(4, 720)\n",
    "\n",
    "# Initialize a variable to store the last time an image was acquired\n",
    "last_image_time = time.time()\n",
    "result, image = cam.read()\n",
    "\n",
    "state = 1\n",
    "should_break = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793aef31-e678-4e01-9426-89dc85bd27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(image):\n",
    "    \"\"\"    \n",
    "    Preprocess an image for use in computer vision applications.\n",
    "    \n",
    "    Arguments:\n",
    "    image : The input image to be preprocessed.\n",
    "        \n",
    "    Returns:\n",
    "    filtered_image : The preprocessed image.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale for filtering.\n",
    "    image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply bilateral filtering to reduce noise while preserving edges.\n",
    "    bilateral = cv2.bilateralFilter(image_grey, d=5, sigmaColor=25, sigmaSpace=25)\n",
    "    \n",
    "    # Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) for enhancing details.\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    filtered_image1 = clahe.apply(bilateral)\n",
    "    \n",
    "    # Apply Gaussian blur to further use \n",
    "    filtered_image = cv2.GaussianBlur(filtered_image1, (5, 5), 0)\n",
    "    \n",
    "    return filtered_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc612ab-a5cc-4290-8a1e-a9fa0a0e31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_info(keypoints, result_image, robot_state):\n",
    "    \"\"\"\n",
    "    Update the essential information to describe the state of the robot.\n",
    "    \n",
    "    Arguments:\n",
    "        keypoints: Detected keypoints representing potential robot positions.\n",
    "        result_image: The image on which to draw the keypoints.\n",
    "        robot_state: An instance of RobotState containing the coordinates and angle of the robot.\n",
    "        \n",
    "    Returns:\n",
    "        robot_state: The updated RobotState instance.\n",
    "    \"\"\"\n",
    "   \n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = True\n",
    "    params.minCircularity = 0.8\n",
    "    params.maxCircularity = 1\n",
    "        \n",
    "    # Filter by color\n",
    "    params.filterByColor = True\n",
    "\n",
    "    x=y=r=x_big=y_big=r_big=x_small=y_small=r_small=0\n",
    "\n",
    "    # Minimum circle radius we want to detect\n",
    "    small_circle_radius_threshold_max = 14 #(le gros il fais 25 et le petit 18 pour la resolution normale)\n",
    "    small_circle_radius_threshold_min = 5\n",
    "    # Check if any blobs (potential circles) were detected\n",
    "    if keypoints:\n",
    "#---- \n",
    "#     print(f\"{len(keypoints)} blobs detected.\")\n",
    "#----                 \n",
    "        # Draw circles on the original image\n",
    "        for keypoint in keypoints:\n",
    "            x = int(keypoint.pt[0])\n",
    "            y = int(keypoint.pt[1])\n",
    "            r = int(keypoint.size / 2)\n",
    "\n",
    "            if small_circle_radius_threshold_min < r < small_circle_radius_threshold_max:\n",
    "                x_small = x\n",
    "                y_small = y\n",
    "                r_small = r\n",
    "            elif r > small_circle_radius_threshold_max:\n",
    "                x_big = x\n",
    "                y_big = y\n",
    "                r_big = r\n",
    "#----        \n",
    "        # print(robot_state.x,robot_state.y,robot_state.r)\n",
    "   #     print('r_small =', r_small)\n",
    "  #      print('r_big =', r_big)\n",
    "        cv2.circle(result_image, (x_big, y_big), r_big, (255, 0, 255), 8) # just to check on the video\n",
    "        cv2.circle(result_image, (x_small, y_small), r_small, (255, 0, 255), 8) # just to check on the video\n",
    "\n",
    "           # print(r)\n",
    "#----\n",
    "        robot_state.x = x_big\n",
    "        robot_state.y = y_big\n",
    "        #Robot orientation = angle between the trajectorie of the robot and the vertical axis\n",
    "        Vect_dir = (x_small - x_big , y_small - y_big)\n",
    "        Vertical = (0, 1)\n",
    "            \n",
    "        dot_product = Vect_dir[0] * Vertical[0] + Vect_dir[1] * Vertical[1]\n",
    "            \n",
    "        magnitude_dir = math.sqrt(Vect_dir[0]**2 + Vect_dir[1]**2)\n",
    "        magnitude_V = math.sqrt(Vertical[0]**2 + Vertical[1]**2)\n",
    "                \n",
    "        # Angle in radiants\n",
    "        if magnitude_dir != 0 and magnitude_V != 0:\n",
    "            angle_rad = math.acos(dot_product / (magnitude_dir * magnitude_V))\n",
    "        else:\n",
    "            angle_rad = 0\n",
    "        # Convertion in degrees\n",
    "        robot_state.angle = math.degrees(angle_rad)\n",
    "# ---\n",
    "#print(robot_state.angle)\n",
    "#---\n",
    "    return robot_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfef5207-3407-45aa-b54d-20e775bd5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def grid_setting(filtered_image, center_matrix, state_matrix):\n",
    "    BLACK = 1\n",
    "    WHITE = 0\n",
    "    black_threshold = 55\n",
    "    white_threshold = 136\n",
    "    red_threshold_inf = 56\n",
    "    red_threshold_sup = 135\n",
    "    robot_pos_delta_x = 55\n",
    "    robot_pos_delta_y = 55\n",
    "    min_area_threshold = 75000\n",
    "\n",
    "    top_right = top_left = bottom_right = bottom_left =  [0,0]\n",
    "    x_center = y_center = x_end = y_end = 0\n",
    "\n",
    "    contours_image = cv2.Canny(filtered_image, 50, 150, apertureSize=3)\n",
    "    contours, _ = cv2.findContours(contours_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    center_matrix_prev = copy.deepcopy(center_matrix)\n",
    "    state_matrix_prev = copy.deepcopy(state_matrix)\n",
    "    \n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour) > min_area_threshold:\n",
    "            peri = cv2.arcLength(largest_contour, True)\n",
    "            approx = cv2.approxPolyDP(largest_contour, 0.02 * peri, True)\n",
    "            \n",
    "            if len(approx) == 4:\n",
    "                cv2.drawContours(result_image, [approx], -1, (0, 255, 0), 2)\n",
    "                ordered_points = order_points(approx.reshape(4, 2))\n",
    "\n",
    "                destination_points = np.array([\n",
    "                    [0, 0],\n",
    "                    [filtered_image.shape[1] - 1, 0],\n",
    "                    [filtered_image.shape[1] - 1, filtered_image.shape[0] - 1],\n",
    "                    [0, filtered_image.shape[0] - 1]\n",
    "                ], dtype=\"float32\")\n",
    "                \n",
    "                matrix = cv2.getPerspectiveTransform(ordered_points, destination_points)\n",
    "                warped_image = cv2.warpPerspective(filtered_image, matrix, (filtered_image.shape[1], filtered_image.shape[0]))\n",
    "                # Right after you calculate the perspective transformation matrix\n",
    "                inverse_matrix = cv2.invert(matrix)[1]\n",
    "                        \n",
    "                # Compute the cell size using the warped image dimensions\n",
    "                case_width = warped_image.shape[1] // num_cases_x\n",
    "                case_height = warped_image.shape[0] // num_cases_y\n",
    "                \n",
    "                # When mapping the centers back to the original image space\n",
    "                for i in range(num_cases_y):\n",
    "                    for j in range(num_cases_x):\n",
    "                        center_x = j * case_width + case_width // 2\n",
    "                        center_y = i * case_height + case_height // 2\n",
    "                        \n",
    "                        # Convert to a floating-point type\n",
    "                        float_center = np.array([[[center_x, center_y]]], dtype=np.float32)\n",
    "                        \n",
    "                        # Map the centers back to the original image space using the inverse matrix\n",
    "                        original_center = cv2.perspectiveTransform(float_center, inverse_matrix)\n",
    "                        original_center = tuple(original_center[0][0].astype(int))\n",
    "                        \n",
    "                        # Draw the cell center on the original image\n",
    "                        cv2.circle(result_image, original_center, 5, (0, 0, 255), -1)\n",
    "                        \n",
    "                        # Update center_matrix with the mapped center\n",
    "                        center_matrix[i][j] = original_center\n",
    "                        \n",
    "                        x_center, y_center = original_center  # Unpack the tuple\n",
    "                        center_value = filtered_image[y_center, x_center]  # Access the image at the y, x coordinates\n",
    "                        debug_matrix[i][j] = center_value  # Store the grayscale value\n",
    "                        #Create the state matrix\n",
    "                        if center_value < black_threshold :\n",
    "                            if abs(x_center-robot_state.x) <= robot_pos_delta_x and abs(y_center-robot_state.y) <= robot_pos_delta_y:\n",
    "                                state_matrix[i][j] = WHITE\n",
    "                            else:\n",
    "                                state_matrix[i][j] = BLACK     \n",
    "                        if center_value > white_threshold:\n",
    "                            state_matrix[i][j] = WHITE\n",
    "                        if red_threshold_inf <= center_value <= red_threshold_sup:\n",
    "                            x_end, y_end = center_matrix[i][j]\n",
    "                            state_matrix[i][j] = WHITE\n",
    "\n",
    "                        \n",
    "    else:\n",
    "        center_matrix = copy.deepcopy(center_matrix_prev)\n",
    "        state_matrix = copy.deepcopy(state_matrix_prev) # comme ca, si on cache on ne detect pas de controu et on garde notre matrice \n",
    "        \n",
    "    return state_matrix, center_matrix, x_end, y_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f2fd1a0-70f8-47fc-918c-2a58dbecc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_plot(num_cases_x,num_cases_y):\n",
    "    \"\"\"\n",
    "    Helper function to create a figure of the desired dimensions & grid\n",
    "    \n",
    "    :param max_val: dimension of the map along the x and y dimensions\n",
    "    :return: the fig and ax objects.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    \n",
    "    major_ticks = np.arange(0, num_cases_x+1, 1)\n",
    "    minor_ticks = np.arange(0, num_cases_y+1, 1)\n",
    "    ax.set_xticks(major_ticks)\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    ax.set_yticks(major_ticks)\n",
    "    ax.set_yticks(minor_ticks, minor=True)\n",
    "    ax.grid(which='minor', alpha=0.2)\n",
    "    ax.grid(which='major', alpha=0.5)\n",
    "    ax.set_ylim([-1,num_cases_y])\n",
    "    ax.set_xlim([-1,num_cases_x])\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7280099a-cd18-464a-beab-541e0954a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_movements_4n():\n",
    "    \"\"\"\n",
    "    Get all possible 4-connectivity movements (up, down, left right).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0)]\n",
    "\n",
    "def _get_movements_8n():\n",
    "    \"\"\"\n",
    "    Get all possible 8-connectivity movements. Equivalent to get_movements_in_radius(1)\n",
    "    (up, down, left, right and the 4 diagonals).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    s2 = math.sqrt(2)\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0),\n",
    "            (1, 1, s2),\n",
    "            (-1, 1, s2),\n",
    "            (-1, -1, s2),\n",
    "            (1, -1, s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c159441-9c43-47e3-8ca2-6cc67964d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle_degrees(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculate the angle in degrees between two points (x1, y1) and (x2, y2).\n",
    "    \"\"\"\n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    angle_rad = math.atan2(delta_y, delta_x)\n",
    "    \n",
    "    # Convert angle to degrees\n",
    "    angle_degrees = math.degrees(angle_rad)\n",
    "    \n",
    "    # Convert angle to be in the range [0, 360)\n",
    "    angle_degrees = angle_degrees % 360\n",
    "    print(angle_degrees)\n",
    "    return angle_degrees\n",
    "\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points (x1, y1) and (x2, y2).\n",
    "    \"\"\"\n",
    "    distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0929679f-11c7-453e-af2f-2fd78948116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_path(cameFrom, current):\n",
    "    \"\"\"\n",
    "    Recurrently reconstructs the path from start node to the current node\n",
    "    :param cameFrom: map (dictionary) containing for each node n the node immediately \n",
    "                     preceding it on the cheapest path from start to n \n",
    "                     currently known.\n",
    "    :param current: current node (x, y)\n",
    "    :return: list of nodes from start to current node\n",
    "    \"\"\"\n",
    "    total_path = [current]\n",
    "    while current in cameFrom.keys():\n",
    "        # Add where the current node came from to the start of the list\n",
    "        total_path.insert(0, cameFrom[current]) \n",
    "        current=cameFrom[current]\n",
    "        \n",
    "#    print(total_path)\n",
    "    return total_path\n",
    "\n",
    "def A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\", num_cases_x=num_cases_x, num_cases_y=num_cases_y):\n",
    "    \"\"\"\n",
    "    A* for 2D occupancy grid. Finds a path from start to goal.\n",
    "    h is the heuristic function. h(n) estimates the cost to reach goal from node n.\n",
    "    :param start: start node (x, y)\n",
    "    :param goal_m: goal node (x, y)\n",
    "    :param occupancy_grid: the grid map\n",
    "    :param movement: select between 4-connectivity ('4N') and 8-connectivity ('8N', default)\n",
    "    :return: a tuple that contains: (the resulting path in meters, the resulting path in data array indices)\n",
    "    \"\"\"\n",
    "    # -----------------------------------------\n",
    "    # DO NOT EDIT THIS PORTION OF CODE\n",
    "    # -----------------------------------------\n",
    "    # Check if the start and goal are within the boundaries of the map\n",
    "  #  for point in [start, goal]: \n",
    "  #      for coord in point:\n",
    "   #         print('coord',coord)\n",
    "   #         assert coord>=0 and coord<=num_cases_x, \"start or end goal not contained in the map\"\n",
    "  #          assert coord>=0 and coord<=num_cases_y, \"start or end goal not contained in the map\"\n",
    "   # \n",
    "    # Check if the start and goal are within the boundaries of the map\n",
    "    for point in [start, goal]:\n",
    "        x_coord, y_coord = point \n",
    "\n",
    "        assert 0 <= x_coord < num_cases_x, \"X-coordinate of start or end goal not contained in the map\"\n",
    "        assert 0 <= y_coord < num_cases_y, \"Y-coordinate of start or end goal not contained in the map\"\n",
    "    \n",
    "    # check if start and goal nodes correspond to free spaces\n",
    "    if occupancy_grid[start[0], start[1]]:\n",
    "        raise Exception('Start node is not traversable')\n",
    "\n",
    "    if occupancy_grid[goal[0], goal[1]]:\n",
    "        raise Exception('Goal node is not traversable')\n",
    "    \n",
    "    # get the possible movements corresponding to the selected connectivity\n",
    "    if movement_type == '4N':\n",
    "        movements = _get_movements_4n()\n",
    "    elif movement_type == '8N':\n",
    "        movements = _get_movements_8n()\n",
    "    else:\n",
    "        raise ValueError('Unknown movement')\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # A* Algorithm implementation - feel free to change the structure / use another pseudo-code\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # The set of visited nodes that need to be (re-)expanded, i.e. for which the neighbors need to be explored\n",
    "    # Initially, only the start node is known.\n",
    "    openSet = [start]\n",
    "    \n",
    "    # The set of visited nodes that no longer need to be expanded.\n",
    "    closedSet = []\n",
    "\n",
    "    # For node n, cameFrom[n] is the node immediately preceding it on the cheapest path from start to n currently known.\n",
    "    cameFrom = dict()\n",
    "\n",
    "    # For node n, gScore[n] is the cost of the cheapest path from start to n currently known.\n",
    "    gScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    gScore[start] = 0\n",
    "\n",
    "    # For node n, fScore[n] := gScore[n] + h(n). map with default value of Infinity\n",
    "    fScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    fScore[start] = h[start]\n",
    "\n",
    "    # while there are still elements to investigate\n",
    "    while openSet != []:\n",
    "        \n",
    "        #the node in openSet having the lowest fScore[] value\n",
    "        fScore_openSet = {key:val for (key,val) in fScore.items() if key in openSet}\n",
    "        current = min(fScore_openSet, key=fScore_openSet.get)\n",
    "        del fScore_openSet\n",
    "        \n",
    "        #If the goal is reached, reconstruct and return the obtained path\n",
    "        if current == goal:\n",
    "#            print(closedSet)\n",
    "            return reconstruct_path(cameFrom, current), closedSet\n",
    "\n",
    "        openSet.remove(current)\n",
    "        closedSet.append(current)\n",
    "        \n",
    "        #for each neighbor of current:\n",
    "        for dx, dy, deltacost in movements:\n",
    "            \n",
    "            neighbor = (current[0]+dx, current[1]+dy)\n",
    "            \n",
    "            # if the node is not in the map, skip\n",
    "            if (neighbor[0] >= occupancy_grid.shape[0]) or (neighbor[1] >= occupancy_grid.shape[1]) or (neighbor[0] < 0) or (neighbor[1] < 0):\n",
    "                continue\n",
    "            \n",
    "            # if the node is occupied or has already been visited, skip\n",
    "            if (occupancy_grid[neighbor[0], neighbor[1]]) or (neighbor in closedSet): \n",
    "                continue\n",
    "                \n",
    "            # d(current,neighbor) is the weight of the edge from current to neighbor\n",
    "            # tentative_gScore is the distance from start to the neighbor through current\n",
    "            tentative_gScore = gScore[current] + deltacost\n",
    "            \n",
    "            if neighbor not in openSet:\n",
    "                openSet.append(neighbor)\n",
    "                \n",
    "            if tentative_gScore < gScore[neighbor]:\n",
    "                # This path to neighbor is better than any previous one. Record it!\n",
    "                cameFrom[neighbor] = current\n",
    "                gScore[neighbor] = tentative_gScore\n",
    "                fScore[neighbor] = gScore[neighbor] + h[neighbor]\n",
    "\n",
    "    # Open set is empty but goal was never reached\n",
    "    print(\"No path found to goal\")\n",
    "    return [], closedSet\n",
    "\n",
    "def truncate_coordinate(center_matrix, X, Y):\n",
    "    threshold_x = 55\n",
    "    threshold_y = 55\n",
    "    num_cases_y, num_cases_x = center_matrix.shape[:2]  # Obtention des dimensions de la matrice\n",
    "\n",
    "    for i in range(num_cases_y):\n",
    "        for j in range(num_cases_x):\n",
    "            diff_x = abs(center_matrix[i, j][0] - X)\n",
    "            diff_y = abs(center_matrix[i, j][1] - Y)\n",
    "\n",
    "            if diff_x <= threshold_x and diff_y <= threshold_y:\n",
    "                x_out, y_out = j, i  \n",
    "  #  for i in range(num_cases_y):\n",
    "   #     for j in range(num_cases_x):\n",
    "    #        \n",
    "     #       if center_matrix[i,j][0] - X <= threshold_x and center_matrix[i,j][1] - Y <= threshold_y:\n",
    "      #          x_out = j\n",
    "       #         y_out = i\n",
    "    \n",
    "#    if y_out == 0: y_out = 5\n",
    " #   if y_out == 1: y_out = 4\n",
    "  #  if y_out == 2: y_out = 3\n",
    "   # if y_out == 3: y_out = 2\n",
    "    #if y_out == 4: y_out = 1\n",
    "    #if y_out == 5: y_out = 0\n",
    "  \n",
    "    return(x_out,y_out)\n",
    "\n",
    "def symetrie_lignes(matrix):\n",
    " \n",
    "    copy_matrix = copy.deepcopy(matrix)\n",
    "    matrix[0,:] = copy_matrix[5,:]\n",
    "    matrix[1,:] = copy_matrix[4,:]\n",
    "    matrix[2,:] = copy_matrix[3,:]\n",
    "    matrix[3,:] = copy_matrix[2,:]\n",
    "    matrix[4,:] = copy_matrix[1,:]\n",
    "    matrix[5,:] = copy_matrix[0,:]\n",
    "    return matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1570848a-4770-47d3-bdb0-c6b6912af1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "async def rotate_robot(client):\n",
    "    global x1 ,y1 ,x2 ,y2, motor_left_target, motor_right_target,angle,move_list,count\n",
    "    angle = calculate_angle_degrees(x1, y1, x2, y2)\n",
    "    print('count =', count)\n",
    "    \n",
    "    if move_list[count] == angle :\n",
    "        angle = 0\n",
    "    else :\n",
    "        move_list[count+1] = angle\n",
    "        angle = angle - move_list[count]\n",
    "        count = count+1\n",
    "    print(move_list)\n",
    "    \n",
    "    if angle < 0 :\n",
    "        angle = -angle\n",
    "        time_rotation = (4.95 * angle) / 180\n",
    "        v = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(-100)],\n",
    "    }\n",
    "        await node.set_variables(v)\n",
    "        await asyncio.sleep(time_rotation)\n",
    "    else:\n",
    "        time_rotation = (4.95 * angle) / 180\n",
    "        if time_rotation == 0 :\n",
    "            v_reverse = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(100)],\n",
    "        }\n",
    "        else :\n",
    "            v_reverse = {\n",
    "                \"motor.left.target\": [int(-100)],\n",
    "                \"motor.right.target\": [int(100)],\n",
    "            }\n",
    "        await node.set_variables(v_reverse)\n",
    "        await asyncio.sleep(time_rotation)\n",
    "    v_stop = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "            \"motor.right.target\": [int(0)],\n",
    "        }\n",
    "    await node.set_variables(v_stop)\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "async def move_robot(client):\n",
    "    global x1 ,y1 ,x2 ,y2, motor_left_target, motor_right_target,distance\n",
    "    distance = calculate_distance(x1, y1, x2, y2)\n",
    "    time_distance = distance*4.5\n",
    "    v = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(100)],\n",
    "    }\n",
    "    await node.set_variables(v)\n",
    "    await asyncio.sleep(time_distance)\n",
    "    v_stop = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "            \"motor.right.target\": [int(0)],\n",
    "        }\n",
    "    await node.set_variables(v_stop)\n",
    "def info_robot_cam()\n",
    "    image_not_good = True\n",
    "    while image_not_good: \n",
    "        ret, frame = cam.read()\n",
    "        if ret:\n",
    "            result_image = frame.copy()  # Initialiser result_image avec une copie de l'image actuelle\n",
    "            filtered_image = pre_processing(result_image)\n",
    "             # Blob detector parameters for circle detection\n",
    "            params = cv2.SimpleBlobDetector_Params()\n",
    "            \n",
    "            # Create a blob detector with the configured parameters\n",
    "            detector = cv2.SimpleBlobDetector_create(params)\n",
    "            \n",
    "            # Detect blobs in the image\n",
    "            keypoints = detector.detect(filtered_image)\n",
    "            \n",
    "            # Update the info about the robot\n",
    "            robot_state = robot_info(keypoints, result_image, robot_state)\n",
    "    \n",
    "            state_matrix, center_matrix, x_end, y_end = grid_setting(filtered_image,center_matrix,state_matrix)\n",
    "            \n",
    "            state_matrix = np.array(state_matrix)\n",
    "            data = symetrie_lignes(state_matrix)\n",
    "\n",
    "            for i in range(num_cases_y):\n",
    "                for j in range(num_cases_x):\n",
    "                    if state_matrix[i][j] != None: \n",
    "                        image_not_good = False\n",
    "        else:\n",
    "            print('no image found')\n",
    "            image_not_good = False\n",
    "\n",
    "    cam.release()\n",
    "return data, center_matrix, x_end, y_end, robot_state, result_image\n",
    "async def A_star_move(client):\n",
    "    global x1, y1, x2, y2, motor_left_target, motor_right_target, move_list\n",
    "    path, visitedNodes = A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\")\n",
    "    print(len(path))\n",
    "    move_list = [0] * len(path)\n",
    "    print(move_list)\n",
    "    for i in range(len(path)-1):\n",
    "        x1, y1 = path[i]\n",
    "        x2, y2 = path[i + 1]\n",
    "        info_robot_cam()\n",
    "        #state1, state2, state3 = filter(self, camera_pos, speed)\n",
    "        #pid()\n",
    "\n",
    "        rotate_task = asyncio.create_task(rotate_robot(client))\n",
    "        await rotate_task\n",
    "        drive_task = asyncio.create_task(move_robot(client))\n",
    "    # Wait for both tasks to complete\n",
    "        await drive_task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6de3df-21a3-4132-80b5-b4db3c43c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b854348-6e19-47b2-b801-f403691b688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal (2, 0)\n",
      "start (1, 2)\n",
      "6\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "180.0\n",
      "count = 0\n",
      "[0, 180.0, 0, 0, 0, 0]\n",
      "270.0\n",
      "count = 1\n",
      "[0, 180.0, 270.0, 0, 0, 0]\n",
      "270.0\n",
      "count = 2\n",
      "[0, 180.0, 270.0, 0, 0, 0]\n",
      "0.0\n",
      "count = 2\n",
      "[0, 180.0, 270.0, 0.0, 0, 0]\n",
      "0.0\n",
      "count = 3\n",
      "[0, 180.0, 270.0, 0.0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 17:52:15.395 Python[10809:492554] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    start_time = time.time()  # Record the start time\n",
    "    ret, frame = cam.read()\n",
    "    if ret:\n",
    "        result_image = frame.copy()  # Initialiser result_image avec une copie de l'image actuelle\n",
    "        \n",
    "        filtered_image = pre_processing(result_image)\n",
    "        plt.imshow(cv2.cvtColor(filtered_image, cv2.COLOR_BGR2RGB))\n",
    "        # Blob detector parameters for circle detection\n",
    "        params = cv2.SimpleBlobDetector_Params()\n",
    "        \n",
    "        # Create a blob detector with the configured parameters\n",
    "        detector = cv2.SimpleBlobDetector_create(params)\n",
    "        \n",
    "        # Detect blobs in the image\n",
    "        keypoints = detector.detect(filtered_image)\n",
    "        \n",
    "        # Update the info about the robot\n",
    "        robot_state = robot_info(keypoints, result_image, robot_state)\n",
    "\n",
    "        state_matrix, center_matrix, x_end, y_end = grid_setting(filtered_image,center_matrix,state_matrix)\n",
    "        \n",
    "        state_matrix = np.array(state_matrix)\n",
    "        data = symetrie_lignes(state_matrix)\n",
    "\n",
    "        if state == 0 :\n",
    "            continue\n",
    "        elif state == 1 :\n",
    "            for i in range(num_cases_y):\n",
    "                if should_break:  # Vérifiez si nous devons sortir de la boucle externe\n",
    "                    break\n",
    "\n",
    "                for j in range(num_cases_x):\n",
    "                    if state_matrix[i][j] == None:\n",
    "                        should_break = True  # Préparez-vous à sortir des deux boucles\n",
    "                        break  # Sortez de la boucle interne\n",
    "                        \n",
    "            fig, ax = create_empty_plot(num_cases_x,num_cases_y)\n",
    "\n",
    "            # Creating the occupancy grid\n",
    "            center_matrix_array = np.array(center_matrix)\n",
    "            center_matrix_array = symetrie_lignes(center_matrix_array)\n",
    "                \n",
    "            cmap = colors.ListedColormap(['white', 'red']) # Select the colors with which to display obstacles and free cells    \n",
    "                \n",
    "            # Converting the random values into occupied and free cells\n",
    "            limit = 0\n",
    "            occupancy_grid = data.copy()\n",
    "\n",
    "            \n",
    "            occupancy_grid[data>limit] = 1\n",
    "            occupancy_grid[data<=limit] = 0\n",
    "            occupancy_grid= occupancy_grid.transpose()\n",
    "\n",
    "            # Displaying the map\n",
    "            ax.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "            plt.title(\"Map : free cells in white, occupied cells in red\");\n",
    "            start_x = robot_state.x\n",
    "            start_y = robot_state.y\n",
    "            start = truncate_coordinate(center_matrix_array,robot_state.x, robot_state.y)\n",
    "            goal = truncate_coordinate(center_matrix_array, x_end, y_end)\n",
    "        \n",
    "            print('goal',goal)\n",
    "            print('start',start)\n",
    "            \n",
    "            x,y = np.mgrid[0:num_cases_x:1, 0:num_cases_y:1]\n",
    "            pos = np.empty(x.shape + (2,))\n",
    "            pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "            pos = np.reshape(pos, (x.shape[0]*x.shape[1], 2))\n",
    "            coords = list([(int(x[0]), int(x[1])) for x in pos])\n",
    "\n",
    "            # Run the A* algorithm\n",
    "            h = np.linalg.norm(pos - goal, axis=-1)\n",
    "            h = dict(zip(coords, h))\n",
    "            path, visitedNodes = A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\")\n",
    "            path = np.array(path).reshape(-1, 2).transpose()\n",
    "            visitedNodes = np.array(visitedNodes).reshape(-1, 2).transpose()\n",
    "\n",
    "            # Displaying the map\n",
    "            fig_astar, ax_astar = create_empty_plot(num_cases_x,num_cases_y)\n",
    "            ax_astar.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "\n",
    "            # Plot the best path found and the list of visited nodes\n",
    "            ax_astar.scatter(visitedNodes[0], visitedNodes[1], marker=\"o\", color = 'orange');\n",
    "            ax_astar.plot(path[0], path[1], marker=\"o\", color = 'blue');\n",
    "            ax_astar.scatter(start[0], start[1], marker=\"o\", color = 'green', s=200);\n",
    "            ax_astar.scatter(goal[0], goal[1], marker=\"o\", color = 'purple', s=200);\n",
    "            \n",
    "            # Displaying the map\n",
    "            fig_astar, ax_astar = create_empty_plot(num_cases_x,num_cases_y)\n",
    "            ax_astar.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "                \n",
    "            # Plot the best path found and the list of visited nodes\n",
    "            ax_astar.scatter(visitedNodes[0], visitedNodes[1], marker=\"o\", color = 'orange');\n",
    "            ax_astar.plot(path[0], path[1], marker=\"o\", color = 'blue');\n",
    "            ax_astar.scatter(start[0], start[1], marker=\"o\", color = 'green', s=200);\n",
    "            ax_astar.scatter(goal[0], goal[1], marker=\"o\", color = 'purple', s=200);\n",
    "            \n",
    "            state = 2\n",
    "\n",
    "            async def main():\n",
    "                do_task = asyncio.create_task(A_star_move(client))\n",
    "                await do_task\n",
    "            await main()     \n",
    "        cv2.imshow('Live Footage', result_image)\n",
    "\n",
    "        #if you click on any key it stops the program\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "#-----        \n",
    "  #      print(state_matrix)\n",
    "#-----\n",
    "            # Wait until a second has passed since the start of the iteration\n",
    "        while time.time() - start_time < 1:\n",
    "            time.sleep(0.01) \n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the camera and close the window\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(1, 5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76435c62-5b7f-4687-896b-e92352e1ab9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
