{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70684718-1daa-4551-8393-57b13538ba83",
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/test-filter.ipynb Cellule 1\u001b[0m line \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/test-filter.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtdmclient\u001b[39;00m \u001b[39mimport\u001b[39;00m ClientAsync, aw\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/test-filter.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m client \u001b[39m=\u001b[39m ClientAsync()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/test-filter.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m client\u001b[39m.\u001b[39mwait_for_node()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/Robotics/MobileRobotics/test-filter.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mawait\u001b[39;00m node\u001b[39m.\u001b[39mlock()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project1-grading/lib/python3.9/site-packages/tdmclient/clientasync.py:106\u001b[0m, in \u001b[0;36mClientAsync.wait_for_node\u001b[0;34m(self, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     sleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEFAULT_SLEEP)\n\u001b[1;32m    105\u001b[0m     time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEFAULT_SLEEP\n\u001b[0;32m--> 106\u001b[0m \u001b[39myield\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import asyncio\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ExtendedKalmanFilter import EKF\n",
    "import IPython.display as Disp\n",
    "from ipywidgets import widgets\n",
    "\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5914f008-3e57-4ec3-8831-a94391c8f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global initialization \n",
    "x_end = y_end=0\n",
    "# All coordonates are initialized to 0\n",
    "class RobotState:\n",
    "    def __init__(self, x=0, y=0, r=0, angle=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.angle = angle \n",
    "\n",
    "robot_state = RobotState()\n",
    "\n",
    "\n",
    "# size of our environment grid\n",
    "num_cases_x = 8  # horizontal cells (valeur arbitraire ici juste pour que ca marche dans mon exemple) \n",
    "num_cases_y = 6   # vertical cells\n",
    "\n",
    "# Initializing our matrix containing the environment information\n",
    "center_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)] #jsp si c'est comme ca qu'on initialise a zero une matrice\n",
    "state_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)]\n",
    "debug_matrix = [[None for _ in range(num_cases_x)] for _ in range(num_cases_y)]\n",
    "\n",
    "#camera related initialization \n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "#Lower the resolution\n",
    "cam.set(3, 1280)\n",
    "cam.set(4, 720)\n",
    "\n",
    "# Initialize a variable to store the last time an image was acquired\n",
    "#last_image_time = time.time()\n",
    "#result, image = cam.read()\n",
    "\n",
    "state = 1\n",
    "should_break = False\n",
    "\n",
    "# initialize filter\n",
    "ekf = None\n",
    "last_time = time.monotonic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_time():\n",
    "    \"\"\"Updates the last time checkpoint and returns the time spent since\"\"\"\n",
    "    global last_time\n",
    "    time_now = time.monotonic()\n",
    "    dt = time_now-last_time\n",
    "    last_time = time_now\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5167a2fc-01c7-4730-b025-c2f100fa456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle_degrees(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculate the angle in degrees between two points (x1, y1) and (x2, y2).\n",
    "    \"\"\"\n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    angle_rad = math.atan2(delta_y, delta_x)\n",
    "    \n",
    "    # Convert angle to degrees\n",
    "    angle_degrees = math.degrees(angle_rad)\n",
    "\n",
    "    return angle_degrees\n",
    "\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points (x1, y1) and (x2, y2).\n",
    "    \"\"\"\n",
    "    distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "793aef31-e678-4e01-9426-89dc85bd27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(image):\n",
    "    \"\"\"    \n",
    "    Preprocess an image for use in computer vision applications.\n",
    "    \n",
    "    Arguments:\n",
    "    image : The input image to be preprocessed.\n",
    "        \n",
    "    Returns:\n",
    "    filtered_image : The preprocessed image.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale for filtering.\n",
    "    image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply bilateral filtering to reduce noise while preserving edges.\n",
    "    bilateral = cv2.bilateralFilter(image_grey, d=5, sigmaColor=25, sigmaSpace=25)\n",
    "    \n",
    "    # Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) for enhancing details.\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    filtered_image = clahe.apply(bilateral)\n",
    "    \n",
    "    return filtered_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc612ab-a5cc-4290-8a1e-a9fa0a0e31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_info(keypoints, result_image,params):\n",
    "    global robot_state\n",
    "    \"\"\"\n",
    "    Update the essential information to describe the state of the robot.\n",
    "    \n",
    "    Arguments:\n",
    "        keypoints: Detected keypoints representing potential robot positions.\n",
    "        result_image: The image on which to draw the keypoints.\n",
    "        robot_state: An instance of RobotState containing the coordinates and angle of the robot.\n",
    "        \n",
    "    Returns:\n",
    "        robot_state: The updated RobotState instance.\n",
    "    \"\"\"\n",
    "   \n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = True\n",
    "    params.minCircularity = 0.8\n",
    "    params.maxCircularity = 1\n",
    "        \n",
    "    # Filter by color\n",
    "    params.filterByColor = True\n",
    "\n",
    "    x=y=r=x_big=y_big=r_big=x_small=y_small=r_small=0 # peut etre je peux enlever ca \n",
    "    d = float('inf')\n",
    "    # Minimum circle radius we want to detect\n",
    "    small_circle_radius_threshold_max = 14 #(le gros il fais 25 et le petit 18 pour la resolution normale)\n",
    "    small_circle_radius_threshold_min = 5\n",
    "    # Check if any blobs (potential circles) were detected\n",
    "    if keypoints:\n",
    "#---- \n",
    "#     print(f\"{len(keypoints)} blobs detected.\")\n",
    "#----                 \n",
    "        # Draw circles on the original image\n",
    "        for keypoint in keypoints:\n",
    "            x = int(keypoint.pt[0])\n",
    "            y = int(keypoint.pt[1])\n",
    "            r = int(keypoint.size / 2)\n",
    "\n",
    "            if small_circle_radius_threshold_min < r < small_circle_radius_threshold_max:\n",
    "                x_small = x\n",
    "                y_small = y\n",
    "                r_small = r\n",
    "            elif r > small_circle_radius_threshold_max:\n",
    "                x_big = x\n",
    "                y_big = y\n",
    "                r_big = r\n",
    "#----        \n",
    "        #print('x/y big', x_big, y_big)\n",
    "        #print('x/y small', x_small, y_small)\n",
    "\n",
    "        # print(robot_state.x,robot_state.y,robot_state.r)\n",
    "   #     print('r_small =', r_small)\n",
    "  #      print('r_big =', r_big)\n",
    "        cv2.circle(result_image, (x_big, y_big), r_big, (255, 0, 255), 8) # just to check on the video\n",
    "        cv2.circle(result_image, (x_small, y_small), r_small, (255, 0, 255), 8) # just to check on the video\n",
    "\n",
    "           # print(r)\n",
    "#----\n",
    "        robot_state.x = x_big\n",
    "        robot_state.y = y_big\n",
    "        \n",
    "        #Robot orientation = angle between the trajectorie of the robot and the vertical axis\n",
    "        robot_state.angle = - calculate_angle_degrees(x_big, y_big, x_small, y_small)\n",
    "\n",
    "        d= calculate_distance(x_small, y_small, x_big,y_big)\n",
    "        \n",
    "\n",
    "    return robot_state, d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80148a6-7eaa-43f0-9cdb-9020b25f5245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_robot_cam():\n",
    "    \"\"\"\n",
    "    Update the essential informations to describe the state of the robot and of the map.\n",
    "    \n",
    "    Arguments:\n",
    "       \n",
    "    Returns:\n",
    "        robot_state: The updated RobotState instance.\n",
    "        center_matrix:\n",
    "        x_end, y_end:\n",
    "        result_image: Image with all the analysis \n",
    "    \"\"\"\n",
    "    #global robot_state, result_image, center_matrix, state_matrix,x_end,y_end, data\n",
    "    global center_matrix, state_matrix\n",
    "    image_not_good = True\n",
    "    while image_not_good: \n",
    "        image_not_good = False\n",
    "        ret, frame = cam.read()\n",
    "        if ret:\n",
    "            result_image = frame.copy()  # Initialiser result_image avec une copie de l'image actuelle\n",
    "            filtered_image = pre_processing(result_image)\n",
    "             # Blob detector parameters for circle detection\n",
    "            params = cv2.SimpleBlobDetector_Params()\n",
    "            \n",
    "            # Create a blob detector with the configured parameters\n",
    "            detector = cv2.SimpleBlobDetector_create(params)\n",
    "            \n",
    "            # Detect blobs in the image\n",
    "            keypoints = detector.detect(filtered_image)\n",
    "            \n",
    "            # Update the info about the robot\n",
    "            robot_state, d = robot_info(keypoints, result_image,params)\n",
    "    \n",
    "            state_matrix, center_matrix, x_end, y_end =grid_setting(filtered_image, result_image)\n",
    "            \n",
    "            state_matrix = np.array(state_matrix)\n",
    "            data = symetrie_lignes(state_matrix)\n",
    "            for i in range(num_cases_y):\n",
    "                for j in range(num_cases_x):\n",
    "                    if (state_matrix[i][j] == None) or d>100: #and (x_end ==0 or y_end == 0)\n",
    "                        image_not_good = True\n",
    "        else:\n",
    "            print('no image found')\n",
    "            image_not_good = False\n",
    "            \n",
    "\n",
    "    return data, center_matrix, x_end, y_end, robot_state, result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speed(right, left):\n",
    "    \"\"\"Retrieves the speed of the robot. Constant coefficient to converse speed of motors to units we want\n",
    "    returns: np.array- [linear_speed, angular speed] in pixels/sec and angle/sec\n",
    "    \"\"\"\n",
    "    coeff_lin = 176/7\n",
    "    coeff_angular = 37/200\n",
    "    linear = ((right + left)/2) * coeff_lin\n",
    "    angular = (left - right) * coeff_angular\n",
    "    return np.array([linear, angular])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_call(left, right, dt):\n",
    "    \"\"\"Makes the call to the filter using the initialised ekf\n",
    "        Args:\n",
    "        right: right speed of the motor in thymio unit (same unit as we give the motor)\n",
    "        left: left speed\n",
    "        Returns: estimated positions x, y, angle in pixels, degrees\n",
    "        \"\"\"\n",
    "    global ekf\n",
    "    #dt = update_time()\n",
    "    speed = get_speed(right, left)\n",
    "    _, _, _, _, position, _ = info_robot_cam()\n",
    "    cam_pos = np.array([position.x, position.y, position.angle])\n",
    "    return ekf.filter(cam_pos, speed, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfef5207-3407-45aa-b54d-20e775bd5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    \"\"\"\n",
    "    Orders the corners of a rectangle or quadrilateral in a consistent way: \n",
    "    top-left, top-right, bottom-right, bottom-left. \n",
    "\n",
    "    Parameters:\n",
    "    - pts: A numpy array of four points (x, y)\n",
    "\n",
    "    Returns:\n",
    "    - A reordered numpy array of points in the order [top-left, top-right, bottom-right, bottom-left].\n",
    "    \"\"\"\n",
    "\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = np.diff(pts, axis=1)\n",
    "\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def grid_setting(filtered_image, result_image):\n",
    "    \"\"\"\n",
    "    Processes a filtered image to identify and analyze a grid, which is assumed to be the largest detected contour.\n",
    "\n",
    "    Parameters:\n",
    "    - filtered_image: A pre-processed image where contours can be easily detected, typically a grayscale or thresholded image.\n",
    "\n",
    "    Returns:\n",
    "    - The updated state matrix, center matrix, and the end coordinates of a specific goal within the grid.\n",
    "    \"\"\"\n",
    "    global center_matrix, state_matrix\n",
    "    #local variables used for the good detection of the different parts of the grid\n",
    "    BLACK = 1\n",
    "    WHITE = 0\n",
    "    black_threshold = 40\n",
    "    white_threshold = 101\n",
    "    red_threshold_inf = 41\n",
    "    red_threshold_sup = 90\n",
    "    robot_pos_delta_x = 55\n",
    "    robot_pos_delta_y = 55\n",
    "    min_area_threshold = 75000\n",
    "    \n",
    "    x_center = y_center = x_end = y_end = 0\n",
    "\n",
    "    contours_image = cv2.Canny(filtered_image, 50, 150, apertureSize=3)\n",
    "    contours, _ = cv2.findContours(contours_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    center_matrix_prev = copy.deepcopy(center_matrix)\n",
    "    state_matrix_prev = copy.deepcopy(state_matrix)\n",
    "\n",
    "    x_end_prev = x_end\n",
    "    y_end_prev = y_end\n",
    "    \n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour) > min_area_threshold:\n",
    "            \n",
    "            # We first approximate the contour to a rectangle\n",
    "            peri = cv2.arcLength(largest_contour, True) #return the perimeter of our contour \n",
    "            approx = cv2.approxPolyDP(largest_contour, 0.02 * peri, True)  #return the number of the corners of the detected shape\n",
    "            #0.02* peri: This value represents the maximum distance between the original curve and its approximation\n",
    "            \n",
    "            if len(approx) == 4:\n",
    "                cv2.drawContours(result_image, [approx], -1, (0, 255, 0), 2)\n",
    "                \n",
    "                ordered_points = order_points(approx.reshape(4, 2))\n",
    "                destination_points = np.array([\n",
    "                    [0, 0],\n",
    "                    [filtered_image.shape[1] - 1, 0],\n",
    "                    [filtered_image.shape[1] - 1, filtered_image.shape[0] - 1],\n",
    "                    [0, filtered_image.shape[0] - 1]\n",
    "                ], dtype=\"float32\")\n",
    "                \n",
    "                matrix = cv2.getPerspectiveTransform(ordered_points, destination_points)\n",
    "                warped_image = cv2.warpPerspective(filtered_image, matrix, (filtered_image.shape[1], filtered_image.shape[0]))\n",
    "                inverse_matrix = cv2.invert(matrix)[1]\n",
    "\n",
    "                #----------- DISPLAY THE TRANSFORMED IMAGE\n",
    "                # Convert the image from BGR to RGB format (OpenCV loads images in BGR by default)\n",
    "             #   warped_image_rgb = cv2.cvtColor(warped_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Display the image in the Jupyter Notebook\n",
    "               # display(Image(data=warped_image_rgb))\n",
    "\n",
    "                #------------\n",
    "                        \n",
    "                case_width = warped_image.shape[1] // num_cases_x\n",
    "                case_height = warped_image.shape[0] // num_cases_y\n",
    "\n",
    "                #correction\n",
    "                distortion_corr = np.array([0.9501, 0.9740, 0.9876, 1, 1.0064, 1.0092, 1.0152, 1.0164])\n",
    "                for i in range(num_cases_y):\n",
    "                    for j in range(num_cases_x):\n",
    "                        center_x = j * case_width * distortion_corr[j] + case_width // 2\n",
    "                        center_y = i * case_height + case_height // 2\n",
    "\n",
    "                        #conversion in a numpy array of type float32 as this format is required by OpenCV functions for transformations.\n",
    "                        float_center = np.array([[[center_x, center_y]]], dtype=np.float32)\n",
    "                        \n",
    "                        original_center = cv2.perspectiveTransform(float_center, inverse_matrix)\n",
    "                        original_center = tuple(original_center[0][0].astype(int))\n",
    "                        \n",
    "                        cv2.circle(result_image, original_center, 5, (0, 0, 255), -1)\n",
    "                        \n",
    "                        center_matrix[i][j] = original_center\n",
    "                        \n",
    "                        x_center, y_center = original_center  \n",
    "                        center_value = filtered_image[y_center, x_center]  \n",
    "                        debug_matrix[i][j] = center_value \n",
    "                #        print('debug',debug_matrix)\n",
    "                        if center_value < black_threshold :\n",
    "                            if abs(x_center-robot_state.x) <= robot_pos_delta_x and abs(y_center-robot_state.y) <= robot_pos_delta_y:\n",
    "                                state_matrix[i][j] = WHITE\n",
    "                            else:\n",
    "                                state_matrix[i][j] = BLACK     \n",
    "                        if center_value > white_threshold:\n",
    "                            state_matrix[i][j] = WHITE\n",
    "                        if red_threshold_inf <= center_value <= red_threshold_sup:\n",
    "                            x_end, y_end = center_matrix[i][j]\n",
    "                            state_matrix[i][j] = WHITE\n",
    "    else:\n",
    "        center_matrix = copy.deepcopy(center_matrix_prev)\n",
    "        state_matrix = copy.deepcopy(state_matrix_prev) \n",
    "        x_end = x_end_prev\n",
    "        y_end = y_end_prev\n",
    "        \n",
    "    return state_matrix, center_matrix, x_end, y_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f2fd1a0-70f8-47fc-918c-2a58dbecc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_plot(num_cases_x,num_cases_y):\n",
    "    \"\"\"\n",
    "    Helper function to create a figure of the desired dimensions & grid\n",
    "    \n",
    "    :param max_val: dimension of the map along the x and y dimensions\n",
    "    :return: the fig and ax objects.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    \n",
    "    major_ticks = np.arange(0, num_cases_x+1, 1)\n",
    "    minor_ticks = np.arange(0, num_cases_y+1, 1)\n",
    "    ax.set_xticks(major_ticks)\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    ax.set_yticks(major_ticks)\n",
    "    ax.set_yticks(minor_ticks, minor=True)\n",
    "    ax.grid(which='minor', alpha=0.2)\n",
    "    ax.grid(which='major', alpha=0.5)\n",
    "    ax.set_ylim([-1,num_cases_y])\n",
    "    ax.set_xlim([-1,num_cases_x])\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7280099a-cd18-464a-beab-541e0954a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_movements_4n():\n",
    "    \"\"\"\n",
    "    Get all possible 4-connectivity movements (up, down, left right).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0)]\n",
    "\n",
    "def _get_movements_8n():\n",
    "    \"\"\"\n",
    "    Get all possible 8-connectivity movements. Equivalent to get_movements_in_radius(1)\n",
    "    (up, down, left, right and the 4 diagonals).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    s2 = math.sqrt(2)\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0),\n",
    "            (1, 1, s2),\n",
    "            (-1, 1, s2),\n",
    "            (-1, -1, s2),\n",
    "            (1, -1, s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0929679f-11c7-453e-af2f-2fd78948116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_path(cameFrom, current):\n",
    "    \"\"\"\n",
    "    Recurrently reconstructs the path from start node to the current node\n",
    "    :param cameFrom: map (dictionary) containing for each node n the node immediately \n",
    "                     preceding it on the cheapest path from start to n \n",
    "                     currently known.\n",
    "    :param current: current node (x, y)\n",
    "    :return: list of nodes from start to current node\n",
    "    \"\"\"\n",
    "    total_path = [current]\n",
    "    while current in cameFrom.keys():\n",
    "        # Add where the current node came from to the start of the list\n",
    "        total_path.insert(0, cameFrom[current]) \n",
    "        current=cameFrom[current]\n",
    "        \n",
    "    return total_path\n",
    "\n",
    "def A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\", num_cases_x=num_cases_x, num_cases_y=num_cases_y):\n",
    "    \"\"\"\n",
    "    A* for 2D occupancy grid. Finds a path from start to goal.\n",
    "    h is the heuristic function. h(n) estimates the cost to reach goal from node n.\n",
    "    :param start: start node (x, y)\n",
    "    :param goal_m: goal node (x, y)\n",
    "    :param occupancy_grid: the grid map\n",
    "    :param movement: select between 4-connectivity ('4N') and 8-connectivity ('8N', default)\n",
    "    :return: a tuple that contains: (the resulting path in meters, the resulting path in data array indices)\n",
    "    \"\"\"\n",
    "    # Check if the start and goal are within the boundaries of the map\n",
    "    for point in [start, goal]:\n",
    "        x_coord, y_coord = point \n",
    "\n",
    "        assert 0 <= x_coord < num_cases_x, \"X-coordinate of start or end goal not contained in the map\"\n",
    "        assert 0 <= y_coord < num_cases_y, \"Y-coordinate of start or end goal not contained in the map\"\n",
    "    \n",
    "    # check if start and goal nodes correspond to free spaces\n",
    "    if occupancy_grid[start[0], start[1]]:\n",
    "        raise Exception('Start node is not traversable')\n",
    "\n",
    "    if occupancy_grid[goal[0], goal[1]]:\n",
    "        raise Exception('Goal node is not traversable')\n",
    "    \n",
    "    # get the possible movements corresponding to the selected connectivity\n",
    "    if movement_type == '4N':\n",
    "        movements = _get_movements_4n()\n",
    "    elif movement_type == '8N':\n",
    "        movements = _get_movements_8n()\n",
    "    else:\n",
    "        raise ValueError('Unknown movement')\n",
    " \n",
    "    # The set of visited nodes that need to be (re-)expanded, i.e. for which the neighbors need to be explored\n",
    "    # Initially, only the start node is known.\n",
    "    openSet = [start]\n",
    "    \n",
    "    # The set of visited nodes that no longer need to be expanded.\n",
    "    closedSet = []\n",
    "\n",
    "    # For node n, cameFrom[n] is the node immediately preceding it on the cheapest path from start to n currently known.\n",
    "    cameFrom = dict()\n",
    "\n",
    "    # For node n, gScore[n] is the cost of the cheapest path from start to n currently known.\n",
    "    gScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    gScore[start] = 0\n",
    "\n",
    "    # For node n, fScore[n] := gScore[n] + h(n). map with default value of Infinity\n",
    "    fScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    fScore[start] = h[start]\n",
    "\n",
    "    # while there are still elements to investigate\n",
    "    while openSet != []:\n",
    "        \n",
    "        #the node in openSet having the lowest fScore[] value\n",
    "        fScore_openSet = {key:val for (key,val) in fScore.items() if key in openSet}\n",
    "        current = min(fScore_openSet, key=fScore_openSet.get)\n",
    "        del fScore_openSet\n",
    "        \n",
    "        #If the goal is reached, reconstruct and return the obtained path\n",
    "        if current == goal:\n",
    "#            print(closedSet)\n",
    "            return reconstruct_path(cameFrom, current), closedSet\n",
    "\n",
    "        openSet.remove(current)\n",
    "        closedSet.append(current)\n",
    "        \n",
    "        #for each neighbor of current:\n",
    "        for dx, dy, deltacost in movements:\n",
    "            \n",
    "            neighbor = (current[0]+dx, current[1]+dy)\n",
    "            \n",
    "            # if the node is not in the map, skip\n",
    "            if (neighbor[0] >= occupancy_grid.shape[0]) or (neighbor[1] >= occupancy_grid.shape[1]) or (neighbor[0] < 0) or (neighbor[1] < 0):\n",
    "                continue\n",
    "            \n",
    "            # if the node is occupied or has already been visited, skip\n",
    "            if (occupancy_grid[neighbor[0], neighbor[1]]) or (neighbor in closedSet): \n",
    "                continue\n",
    "                \n",
    "            # d(current,neighbor) is the weight of the edge from current to neighbor\n",
    "            # tentative_gScore is the distance from start to the neighbor through current\n",
    "            tentative_gScore = gScore[current] + deltacost\n",
    "            \n",
    "            if neighbor not in openSet:\n",
    "                openSet.append(neighbor)\n",
    "                \n",
    "            if tentative_gScore < gScore[neighbor]:\n",
    "                # This path to neighbor is better than any previous one. Record it!\n",
    "                cameFrom[neighbor] = current\n",
    "                gScore[neighbor] = tentative_gScore\n",
    "                fScore[neighbor] = gScore[neighbor] + h[neighbor]\n",
    "\n",
    "    # Open set is empty but goal was never reached\n",
    "    print(\"No path found to goal\")\n",
    "    return [], closedSet\n",
    "\n",
    "def truncate_coordinate(center_matrix, X, Y):\n",
    "    \n",
    "    threshold_x = 60\n",
    "    threshold_y = 60\n",
    "    num_cases_y, num_cases_x = center_matrix.shape[:2]  # Obtention des dimensions de la matrice\n",
    "\n",
    "    for i in range(num_cases_y):\n",
    "        for j in range(num_cases_x):\n",
    "            diff_x = abs(center_matrix[i, j][0] - X)\n",
    "            diff_y = abs(center_matrix[i, j][1] - Y)\n",
    "\n",
    "            if diff_x <= threshold_x and diff_y <= threshold_y:\n",
    "                x_out, y_out = j, i  \n",
    "    return(x_out, y_out)\n",
    "\n",
    "def symetrie_lignes(matrix):\n",
    " \n",
    "    copy_matrix = copy.deepcopy(matrix)\n",
    "    matrix[0][:] = copy_matrix[5][:]\n",
    "    matrix[1][:] = copy_matrix[4][:]\n",
    "    matrix[2][:] = copy_matrix[3][:]\n",
    "    matrix[3][:] = copy_matrix[2][:]\n",
    "    matrix[4][:] = copy_matrix[1][:]\n",
    "    matrix[5][:] = copy_matrix[0][:]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe9abe0-7939-44d6-b6c3-6996945398bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motor_set_speed(left_speed, right_speed,node):\n",
    "    aw(node.set_variables(motors(left_speed,right_speed)))\n",
    "    \n",
    "def motors(left_speed, right_speed):\n",
    "    return {\n",
    "        \"motor.left.target\": [left_speed],\n",
    "        \"motor.right.target\": [right_speed],\n",
    "    }\n",
    "def check_obstacle_state(obst):\n",
    "    \"\"\"Checks which next state the robot should go in\n",
    "        0: saw an obstacle\n",
    "        1: normal state\n",
    "        2: corrects trajectory after avoiding obstacle\n",
    "    \"\"\"\n",
    "\n",
    "    global saw_obstacle\n",
    "\n",
    "    obstThr = 500\n",
    "    if all(elements < obstThr for elements in obst):\n",
    "        return 1  # État initial, pas d'obstacle\n",
    "    else:\n",
    "        return 0  # Obstacle détecté\n",
    "\n",
    "def check_kidnapped_state(sensor, state):\n",
    "    global was_kidnapped\n",
    "    tresh = 50\n",
    "    if all(elements < tresh for elements in sensor):\n",
    "        was_kidnapped = True\n",
    "        return 3\n",
    "    if was_kidnapped: # set to reinitialise\n",
    "        was_kidnapped = False\n",
    "        return 2\n",
    "    return state\n",
    "\n",
    "def local_navi(obst):\n",
    "\n",
    "    speed0 = 50      \n",
    "    obstSpeedGain = [6, 4, -2, -6, -8]\n",
    "    spLeft = speed0\n",
    "    spRight = speed0\n",
    "\n",
    "    for i in range(5):\n",
    "        spLeft += obst[i] * obstSpeedGain[i] // 100\n",
    "        spRight += obst[i] * obstSpeedGain[4 - i] // 100\n",
    "\n",
    "    return spLeft, spRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "076da25d-7f5f-45ef-9316-8992c677aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_robot_rect(client,x_a,y_a,x_t,y_t):\n",
    "    global motor_left_target, motor_right_target,distance\n",
    "    x_a = x_a / 100\n",
    "    y_a = y_a / 100\n",
    "    x_t = x_t / 100\n",
    "    y_t = y_t / 100\n",
    "    distance = calculate_distance(x_a, y_a, x_t, y_t)\n",
    "    time_distance = distance*4.5\n",
    "    v = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(100)],\n",
    "    }\n",
    "    aw(node.set_variables(v))\n",
    "    time.sleep(time_distance)\n",
    "    filter_call(100, 100, time_distance)\n",
    "    v_stop = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "            \"motor.right.target\": [int(0)],\n",
    "        }\n",
    "    aw(node.set_variables(v_stop))\n",
    "\n",
    "def rotate_robot_angle(client, angle):\n",
    "    \"\"\"\n",
    "    teta: ,mode, x_a, y_a, x_t, y_t\n",
    "    \"\"\"\n",
    "    global motor_left_target, motor_right_target,move_list,count, ekf\n",
    "    \n",
    "    if angle < 0 :\n",
    "        angle = - angle\n",
    "        time_rotation = (4.95 * angle) / 180\n",
    "        v = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(-100)],\n",
    "    }\n",
    "        aw(node.set_variables(v))\n",
    "        time.sleep(time_rotation)\n",
    "        filter_call(100, -100, time_rotation)\n",
    "        \n",
    "    else:\n",
    "        time_rotation = (4.95 * angle) / 180\n",
    "        if time_rotation == 0 :\n",
    "            v_reverse = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(100)],\n",
    "            }\n",
    "            aw(node.set_variables(v_reverse))\n",
    "            time.sleep(time_rotation)\n",
    "            filter_call(100, 100, time_rotation)\n",
    "        else :\n",
    "            v_reverse = {\n",
    "                \"motor.left.target\": [int(-100)],\n",
    "                \"motor.right.target\": [int(100)],\n",
    "            }\n",
    "            aw(node.set_variables(v_reverse))\n",
    "            time.sleep(time_rotation)\n",
    "            filter_call(-100, 100, time_rotation)\n",
    "        \n",
    "    v_stop = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "            \"motor.right.target\": [int(0)],\n",
    "        }\n",
    "    aw(node.set_variables(v_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71dc1069-f1aa-4298-8128-77b10348acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_angle(angle):\n",
    "    \"\"\"Normalize an angle to the range [-180, 180] degrees.\"\"\"\n",
    "    angle = angle % 360  # Normalize between 0 and 360\n",
    "    if angle > 180:\n",
    "        angle -= 360  # Adjust to the range [-180, 180]\n",
    "    return angle\n",
    "    \n",
    "def correction_1(teta_a,x_a,y_a,x_t,y_t, teta_t):\n",
    "    teta = ( normalize_angle(teta_t - teta_a))\n",
    "    print(\"correction teta\", teta)\n",
    "    rotate_robot_angle(client, teta)\n",
    "\n",
    "# def correction_3(x_a, y_a, teta_a, x_t, y_t, teta_t):\n",
    "#     teta = calculate_angle_degrees(x_a, y_a, x_t, y_t)\n",
    "#     angle1 = teta - teta_a #- 180 \n",
    "#     angle_1 =  normalize_angle(angle1)\n",
    "#     rotate_robot_angle(client, angle_1)\n",
    "    \n",
    "#     move_robot_rect(client, x_a, y_a, x_t, y_t)\n",
    "    \n",
    "#     angle2 =  teta + teta_t# + 180 \n",
    "#     angle_2 = normalize_angle(angle2)\n",
    "#     rotate_robot_angle(client, angle_2)\n",
    "\n",
    "def correction(x_a, y_a, teta_a, x_t,y_t,teta_t, x_t1, y_t1):\n",
    "    \"\"\"Controller that decides what correction to make depending on the distance and angle of estimated\"\"\"\n",
    "    dist = calculate_distance(x_a, y_a, x_t, y_t)\n",
    "    # if teta_a < -165: #-165\n",
    "    #    teta_a = -teta_a\n",
    "    if ((abs(teta_a-teta_t)%360 >5) and (abs(teta_a-teta_t)%360 <350)):\n",
    "        if obstacle_state == 2:\n",
    "            print(\"correction 1.3\")\n",
    "            correction_1(teta_a, x_a,y_a,x_t,y_t,teta_t)\n",
    "            move_robot_rect(client,x_a,y_a,x_t,y_t)\n",
    "        elif abs(x_a-x_t)>15 or abs(y_a-y_t)>15:\n",
    "            print(\"correction 1.1\")\n",
    "            correction_1(teta_a, x_a,y_a,x_t1,y_t1,teta_t)\n",
    "        else:\n",
    "            print(\"correction 1.2\")\n",
    "            correction_1(teta_a, x_a,y_a,x_t,y_t,teta_t)\n",
    "\n",
    "        return\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1570848a-4770-47d3-bdb0-c6b6912af1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "obstacle_state = 1\n",
    "saw_obstacle = False\n",
    "was_kidnapped = False\n",
    "new_angle = 0\n",
    "def rotate_robot(client):\n",
    "    global x1 ,y1 ,x2 ,y2, motor_left_target, motor_right_target,angle,move_list,count\n",
    "    angle = calculate_angle_degrees(x1, y1, x2, y2)\n",
    "    normalize_angle(angle)\n",
    "    if abs(move_list[count] - angle) < 5:\n",
    "        angle = 0\n",
    "    else :\n",
    "        if count+1 < len(move_list):\n",
    "            move_list[count+1] = angle\n",
    "        angle = angle - move_list[count]\n",
    "        count = count+1\n",
    "    \n",
    "    if angle < 0 :\n",
    "        angle = -angle\n",
    "        time_rotation = (4.95 * angle) / 180\n",
    "        v = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(-100)],\n",
    "        }\n",
    "        aw(node.set_variables(v))\n",
    "        time.sleep(time_rotation)\n",
    "        filter_call(100, -100, time_rotation)\n",
    "\n",
    "    else:\n",
    "        time_rotation = (4.95 * angle) / 180\n",
    "        if time_rotation == 0 :\n",
    "            v_reverse = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(100)],\n",
    "            }\n",
    "            filter_call(100, 100, time_rotation)\n",
    "\n",
    "        else :\n",
    "            v_reverse = {\n",
    "                \"motor.left.target\": [int(-100)],\n",
    "                \"motor.right.target\": [int(100)],\n",
    "            }\n",
    "            filter_call(-100, 100, time_rotation)\n",
    "\n",
    "        aw(node.set_variables(v_reverse))\n",
    "        time.sleep(time_rotation)\n",
    "    v_stop = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "            \"motor.right.target\": [int(0)],\n",
    "        }\n",
    "    aw(node.set_variables(v_stop))\n",
    "     \n",
    "def move_robot(client):\n",
    "    global x1 ,y1 ,x2 ,y2, motor_left_target, motor_right_target,distance\n",
    "    distance = calculate_distance(x1, y1, x2, y2)\n",
    "    time_distance = distance*1.6\n",
    "    v = {\n",
    "            \"motor.left.target\": [int(100)],\n",
    "            \"motor.right.target\": [int(100)],\n",
    "    }\n",
    "    aw(node.set_variables(v))\n",
    "    time.sleep(time_distance)\n",
    "    filter_call(100, 100, time_distance)\n",
    "    v_stop = {\n",
    "            \"motor.left.target\": [int(0)],\n",
    "            \"motor.right.target\": [int(0)],\n",
    "        }\n",
    "    aw(node.set_variables(v_stop))\n",
    "#LOCAL NAVIGATION CHECK\n",
    "    \n",
    "\n",
    "\n",
    "def A_star_move(client):\n",
    "    global x1, y1, x2, y2, motor_left_target, motor_right_target, move_list,obstacle_state,prox_ground_delta, prox_horizontal,obst, obstThrH, obstThrL, obstSpeedGain, speed0, speedGain, robot_state, saw_obstacle, x_end, was_kidnapped\n",
    "    goal = None\n",
    "    data, center_matrix, x_end, y_end, robot_state, result_image = info_robot_cam()\n",
    "\n",
    "\n",
    "    while True :\n",
    "        if obstacle_state == 1 :\n",
    "            _, _, _, _, robot_state, _ = info_robot_cam()\n",
    "\n",
    "            fig, ax = create_empty_plot(num_cases_x,num_cases_y)\n",
    "             # Creating the occupancy grid\n",
    "            center_matrix_array = np.array(center_matrix)\n",
    "            center_matrix_array = symetrie_lignes(center_matrix_array)\n",
    "                \n",
    "            cmap = colors.ListedColormap(['white', 'red']) # Select the colors with which to display obstacles and free cells    \n",
    "                \n",
    "            # Converting the random values into occupied and free cells\n",
    "            limit = 0\n",
    "            occupancy_grid = data.copy()\n",
    "    \n",
    "            \n",
    "            occupancy_grid[data>limit] = 1\n",
    "            occupancy_grid[data<=limit] = 0\n",
    "            occupancy_grid= occupancy_grid.transpose()\n",
    "    \n",
    "            # Displaying the map\n",
    "            occupancy_grid = occupancy_grid.astype(float)\n",
    "            ax.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "            plt.title(\"Map : free cells in white, occupied cells in red\");\n",
    "            \n",
    "\n",
    "            # Run the A* algorithm\n",
    "             \n",
    "            #ici on fait le check infocam/filtre/pid, car la local nav est une boucle\n",
    "            start_x = robot_state.x\n",
    "            start_y = robot_state.y\n",
    "            start = truncate_coordinate(center_matrix_array,robot_state.x, robot_state.y)\n",
    "            print('x_end',x_end)\n",
    "            print(\"y end\", y_end)\n",
    "            if goal == None:\n",
    "                goal = truncate_coordinate(center_matrix_array, x_end, y_end)\n",
    "                \n",
    "            x,y = np.mgrid[0:num_cases_x:1, 0:num_cases_y:1]\n",
    "            pos = np.empty(x.shape + (2,))\n",
    "            pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "            pos = np.reshape(pos, (x.shape[0]*x.shape[1], 2))\n",
    "            coords = list([(int(x[0]), int(x[1])) for x in pos])\n",
    "            h = np.linalg.norm(pos - goal, axis=-1)\n",
    "            h = dict(zip(coords, h))\n",
    "#            print(occupancy_grid)\n",
    "            print('A star started')\n",
    "            path, visitedNodes = A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"4N\")\n",
    "            path = np.array(path).reshape(-1, 2).transpose()\n",
    "            visitedNodes = np.array(visitedNodes).reshape(-1, 2).transpose()\n",
    "\n",
    "            # Displaying the map\n",
    "            fig_astar, ax_astar = create_empty_plot(num_cases_x,num_cases_y)\n",
    "            ax_astar.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "        \n",
    "            # Plot the best path found and the list of visited nodes\n",
    "            ax_astar.scatter(visitedNodes[0], visitedNodes[1], marker=\"o\", color = 'orange');\n",
    "            ax_astar.plot(path[0], path[1], marker=\"o\", color = 'blue');\n",
    "            ax_astar.scatter(start[0], start[1], marker=\"o\", color = 'green', s=200);\n",
    "            ax_astar.scatter(goal[0], goal[1], marker=\"o\", color = 'purple', s=200);\n",
    "            \n",
    "            # Displaying the map\n",
    "            fig_astar, ax_astar = create_empty_plot(num_cases_x,num_cases_y)\n",
    "            ax_astar.imshow(occupancy_grid.transpose(), cmap=cmap)\n",
    "                \n",
    "            # Plot the best path found and the list of visited nodes\n",
    "            ax_astar.scatter(visitedNodes[0], visitedNodes[1], marker=\"o\", color = 'orange');\n",
    "            ax_astar.plot(path[0], path[1], marker=\"o\", color = 'blue');\n",
    "            ax_astar.scatter(start[0], start[1], marker=\"o\", color = 'green', s=200);\n",
    "            ax_astar.scatter(goal[0], goal[1], marker=\"o\", color = 'purple', s=200);\n",
    "            \n",
    "            move_list = [0] * len(path[0])\n",
    "\n",
    "            for i in range(len(path[1])-1):\n",
    "                x1 = path[0][i]\n",
    "                x2 = path[0][i+1]\n",
    "                y1 = path[1][i]\n",
    "                y2 = path[1][i+1]\n",
    "                if (i+2<len(path[1])):\n",
    "                    x3 = path[0][i+2]\n",
    "                    y3 = path[1][i+2]\n",
    "                \n",
    "                _, center_matrix, _, _, robot_state, result_image = info_robot_cam()\n",
    "                \n",
    "                #state1, state2, state3 = filter(self, camera_pos, speed)\n",
    "\n",
    "                correction(robot_state.x, robot_state.y, robot_state.angle, center_matrix_array[y1][x1][0], center_matrix_array[y1][x1][1], move_list[count], center_matrix_array[y2][x2][0], center_matrix_array[y2][x2][1])\n",
    "\n",
    "                rotate_robot(client)\n",
    "                _, center_matrix, _, _, robot_state, result_image = info_robot_cam()\n",
    "                print('x,y reel',robot_state.x,robot_state.y)\n",
    "                print('x,y theo',center_matrix_array[y1][x1][0],center_matrix_array[y1][x1][1])\n",
    "                print('teta_a , teta_t', robot_state.angle, move_list[count])\n",
    "\n",
    "                for i in range(3):\n",
    "                \n",
    "                    move_robot(client)\n",
    "                    aw(node.wait_for_variables({\"prox.horizontal\"}))\n",
    "                    obst = (list(node.v.prox.horizontal))\n",
    "                    obstacle_state = check_obstacle_state(obst)\n",
    "                    while obstacle_state == 0: \n",
    "                        \n",
    "                        #local navigation\n",
    "                        for i in range(5):\n",
    "                            leftSpeed, rightSpeed = local_navi(obst)\n",
    "                            motor_set_speed(leftSpeed, rightSpeed, node)\n",
    "                            \n",
    "                        motor_set_speed(100,100,node)\n",
    "                        time.sleep(1.5)\n",
    "                        filter_call(100, 100, 1.5)\n",
    "                        motor_set_speed(0,0,node)\n",
    "                        obstacle_state = 2\n",
    "                        _, center_matrix, _, _, robot_state, result_image = info_robot_cam()\n",
    "                        #state1, state2, state3 = filter(self, camera_pos, speed)\n",
    "                        print('angle state', robot_state.angle)\n",
    "                        print('angle theo', move_list[count])\n",
    "                        correction(robot_state.x, robot_state.y, robot_state.angle, center_matrix_array[y3][x3][0], center_matrix_array[y3][x3][1], move_list[count],_, _)\n",
    "                        \n",
    "                        print('angle state', robot_state.angle)\n",
    "                        print('angle theo', move_list[count])\n",
    "                        print('x actuel', robot_state.x)\n",
    "                        print('y actuel', robot_state.y)\n",
    "                        print('x theorique', center_matrix_array[y2][x2][0])\n",
    "                        print('y theorique', center_matrix_array[y2][x2][1])\n",
    "                        \n",
    "                        \n",
    " #                       obstacle_state = check_obstacle_state(obst)\n",
    "                        print(obstacle_state)\n",
    "                        if obstacle_state == 2:\n",
    "                            print('obstacle')\n",
    "                            motor_set_speed(0, 0, node)\n",
    "                            break\n",
    "                    aw(node.wait_for_variables({\"prox.ground.delta\"}))\n",
    "                    ground_sensor = (list(node.v.prox.ground.delta))\n",
    "                    obstacle_state = check_kidnapped_state(ground_sensor, obstacle_state)\n",
    "                    while obstacle_state == 3:\n",
    "                        # kidnapped\n",
    "                        print(\"kidnapped\")\n",
    "                        v_stop = {\n",
    "                            \"motor.left.target\": [int(0)],\n",
    "                            \"motor.right.target\": [int(0)],\n",
    "                        }\n",
    "                        aw(node.set_variables(v_stop))\n",
    "                        aw(node.wait_for_variables({\"prox.ground.reflected\"}))\n",
    "                        ground_sensor = (list(node.v.prox.ground.reflected))\n",
    "                        obstacle_state = check_kidnapped_state(ground_sensor, state)\n",
    "                    if obstacle_state == 2:\n",
    "                        break\n",
    "                if obstacle_state == 2:\n",
    "                    obstacle_state = 1\n",
    "                    break\n",
    "        if abs(robot_state.x - center_matrix_array[goal[0]][goal[1]][0]) < 150 and abs(robot_state.y - center_matrix_array[goal[0]][goal[1]][1]) < 150 :\n",
    "            print(\"done\")\n",
    "            break\n",
    "                    \n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b854348-6e19-47b2-b801-f403691b688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_end 363\n",
      "y end 529\n",
      "A star started\n",
      "x,y reel 892 338\n",
      "x,y theo 902 342\n",
      "teta_a , teta_t 174.28940686250036 180.0\n",
      "correction 1.2\n",
      "correction teta 7.853313301978204\n",
      "x,y reel 782 327\n",
      "x,y theo 793 340\n",
      "teta_a , teta_t -174.0938588862295 180.0\n",
      "x,y reel 672 338\n",
      "x,y theo 686 337\n",
      "teta_a , teta_t 95.71059313749964 90.0\n",
      "x,y reel 663 227\n",
      "x,y theo 689 238\n",
      "teta_a , teta_t -180.0 180.0\n",
      "x,y reel 553 231\n",
      "x,y theo 582 236\n",
      "teta_a , teta_t -178.09084756700364 180.0\n",
      "x,y reel 445 234\n",
      "x,y theo 476 233\n",
      "teta_a , teta_t -82.40535663140857 -90.0\n",
      "x,y reel 455 347\n",
      "x,y theo 473 332\n",
      "teta_a , teta_t -88.09084756700362 -90.0\n",
      "x,y reel 460 457\n",
      "x,y theo 470 431\n",
      "teta_a , teta_t 174.28940686250036 180.0\n",
      "correction 1.1\n",
      "correction teta 7.59464336859142\n",
      "x,y reel 355 446\n",
      "x,y theo 366 429\n",
      "teta_a , teta_t -78.3106308245608 -90.0\n",
      "done\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_star_move(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b788c9c-a47d-49c7-bea2-0b648a4b7e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[923, 923]\n",
      "[923, 923]\n",
      "[923, 923]\n",
      "[923, 923]\n",
      "[923, 923]\n",
      "[923, 923]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ground_sensor \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m(node\u001b[38;5;241m.\u001b[39mv\u001b[38;5;241m.\u001b[39mprox\u001b[38;5;241m.\u001b[39mground\u001b[38;5;241m.\u001b[39mdelta))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(ground_sensor)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    aw(node.wait_for_variables({\"prox.ground.delta\"}))\n",
    "    ground_sensor = (list(node.v.prox.ground.delta))\n",
    "    print(ground_sensor)\n",
    "    time.sleep(0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e20f17-993c-4a8e-98b7-c908a179917d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
